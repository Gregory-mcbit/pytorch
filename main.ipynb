{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "PyTorch is a deep learning framework used for research and development in machine learning and artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor is a fundamental data structure that is similar to arrays or matrices. Tensors are the building blocks of neural networks and are used to represent data in the form of multi-dimensional arrays\n",
    "\n",
    "### Types of Tensors\n",
    "![](./Tensor.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.6731e-01,  4.1031e-01, -1.5540e-01,  ...,  2.0594e-01,\n",
       "          -7.7255e-01, -1.1984e-01],\n",
       "         [-5.6662e-01,  7.0067e-01, -3.4180e-01,  ..., -1.1127e+00,\n",
       "           1.8683e+00, -1.1175e+00],\n",
       "         [ 8.8551e-01, -6.9390e-01,  6.1661e-01,  ...,  9.9827e-01,\n",
       "           5.2346e-01,  1.1848e-01],\n",
       "         ...,\n",
       "         [-1.3863e+00, -1.5750e+00, -9.7003e-01,  ..., -2.8985e-01,\n",
       "           1.1005e+00, -3.1892e-01],\n",
       "         [-4.7203e-01, -2.4616e-01, -1.9265e+00,  ..., -7.0816e-01,\n",
       "          -5.6475e-01, -8.3122e-01],\n",
       "         [-1.1669e+00, -1.0620e-03, -1.9500e-02,  ...,  7.5206e-01,\n",
       "           1.8913e+00,  6.1879e-01]],\n",
       "\n",
       "        [[ 4.6298e-01,  5.4132e-01, -6.9952e-01,  ..., -4.9100e-01,\n",
       "          -7.0300e-01, -6.1826e-01],\n",
       "         [-8.0461e-01, -6.8585e-01, -5.3335e-01,  ..., -5.4940e-02,\n",
       "          -2.2417e-01, -9.4653e-01],\n",
       "         [ 1.5007e+00, -9.9051e-01,  1.6570e-02,  ..., -3.8530e-01,\n",
       "          -2.6853e-01, -4.9141e-01],\n",
       "         ...,\n",
       "         [ 8.4170e-01,  5.9050e-01,  1.0565e+00,  ...,  1.1243e+00,\n",
       "           2.5168e-01, -1.5642e+00],\n",
       "         [ 8.0263e-01, -1.9716e+00, -1.3334e+00,  ...,  2.2510e+00,\n",
       "           2.0635e-01, -2.1207e-01],\n",
       "         [ 6.3797e-01, -7.9496e-01, -2.5321e-01,  ..., -3.2946e-01,\n",
       "          -4.7364e-01, -2.7030e-01]],\n",
       "\n",
       "        [[-3.0399e-01,  1.5003e+00, -2.1852e-01,  ...,  5.6885e-02,\n",
       "           1.5649e+00, -5.1509e-01],\n",
       "         [ 4.6452e-01,  3.7256e-01,  3.8977e-01,  ..., -1.2080e+00,\n",
       "           1.0121e+00, -1.5772e+00],\n",
       "         [ 1.3017e-01, -9.8137e-01, -3.1028e-01,  ...,  7.8474e-01,\n",
       "          -3.5978e-02,  2.8495e-01],\n",
       "         ...,\n",
       "         [ 7.2386e-01,  2.1574e-02,  8.7633e-01,  ..., -5.2339e-01,\n",
       "          -1.3498e+00,  6.1217e-01],\n",
       "         [ 6.8984e-01,  3.0858e-01,  1.1412e+00,  ...,  1.8345e+00,\n",
       "          -9.4012e-01,  2.7153e+00],\n",
       "         [ 7.8942e-01, -3.3977e-01,  9.7477e-01,  ...,  1.6442e-01,\n",
       "          -3.7046e-02, -1.5791e+00]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(42.0)  # Creates a scalar tensor with the value 42.0. has 0 dimensions\n",
    "vector = torch.tensor([1, 2, 3, 4, 5])  # Creates a 1-D tensor with 5 elements\n",
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])  # Creates a 2-D tensor with 2 rows and 3 columns\n",
    "four_dim_tensor = torch.randn(32, 3, 64, 64)  # Create a 4-D tensor with shape (batch_size, channels, height, width)\n",
    "four_dim_tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different arguments can be provided for tensor creation:\n",
    "* Data\n",
    "* Dtype\n",
    "* Device (specify the device (CPU or GPU) on which the tensor should be located using this argument. If not provided, the tensor will be created on the CPU by default.)\n",
    "* Requires_grad (If set to True, the tensor will be set up to track operations on it for automatic differentiation (autograd) during backpropagation. This is useful for gradient-based optimization and training deep learning models.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor(data=[[1, 2, 3], [4, 5, 6]], \n",
    "dtype=torch.float32, \n",
    "device='cpu', \n",
    "requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor(data=[[1, 2, 3], [3, 2, 3]])\n",
    "tensor.type(torch.float32)\n",
    "tensor.numel()  # total elements in tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 3],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor = torch.reshape(tensor, (3, 2))\n",
    "reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 3],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor = torch.reshape(tensor, (-1, 2))  # -1 is used to infer one of dimensions\n",
    "reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1679, -0.4802,  0.6324,  ...,  0.7223, -0.5063, -0.7060],\n",
       "        [ 1.2336,  0.3826,  0.2796,  ..., -0.2616,  0.6765, -0.0804],\n",
       "        [-1.3299,  0.9156, -0.3471,  ...,  0.0298, -0.8025,  0.7965],\n",
       "        ...,\n",
       "        [ 0.9928, -0.0565, -0.2597,  ..., -0.2338,  0.4734,  0.0774],\n",
       "        [-0.2038, -0.8475, -1.2998,  ...,  2.0775,  0.3445,  0.5881],\n",
       "        [-0.6292, -2.4918,  1.1873,  ...,  0.4216,  2.0810,  1.0084]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(32, 3, 64, 64)\n",
    "x_flattened = x.view(x.size(0), -1)\n",
    "x_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_tensor = torch.unsqueeze(tensor, dim=0)  #  Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "expanded_tensor.size(), tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permute function\n",
    "The permute() function allows to rearrange dimensions in a tensor, providing with the flexibility to change the shape and orientation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted_tensor = tensor.permute(1, 0)  # Swap dimensions 0 and 1\n",
    "permuted_tensor.shape, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [3, 2, 3]]),\n",
       " tensor([[1, 3],\n",
       "         [2, 2],\n",
       "         [3, 3]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor, permuted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original tensor shape is: torch.Size([2, 3]),\n",
      "The transposed tensor using .t shape is: torch.Size([3, 2]),\n",
      "The transposed tensor using .tranpose shape is: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Transposing a Tensor (Swapping Rows and Columns)\n",
    "transposed_tensor_1 = tensor.t()\n",
    "transposed_tensor_2 = torch.transpose(tensor, 0, 1)  # Swap axes 0 and 1\n",
    "\n",
    "print(f'The original tensor shape is: {tensor.shape},\\n' \n",
    "      f'The transposed tensor using .t shape is: {transposed_tensor_1.shape},\\n' \n",
    "      f'The transposed tensor using .tranpose shape is: {transposed_tensor_2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition and subtraction between tensors same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9,  9, 10],\n",
       "        [17, 17,  7]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a = torch.tensor([[4, 5, 7], [8, 9, 0]])\n",
    "tensor_b = torch.tensor([[5, 4, 3], [9, 8, 7]])\n",
    "\n",
    "tensor_a + tensor_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1,  1,  4],\n",
       "        [-1,  1, -7]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a - tensor_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element-wise multiplication between 2 tensors of same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20, 20, 21],\n",
       "        [72, 72,  0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a * tensor_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix-wise multiplication (dot product) between 2 tensors where the inner dimensions match (the number of columns in the first tensor equals the number of rows in the second tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 72,  63,  54],\n",
       "        [121, 104,  87]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_c = torch.tensor([[5, 4, 3], [9, 8, 7], [1, 1, 1]])\n",
    "matmu = torch.matmul(tensor_a, tensor_c)\n",
    "matmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8000, 1.2500, 2.3333],\n",
       "        [0.8889, 1.1250, 0.0000]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div = tensor_a / tensor_b\n",
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     1024,       625,       343],\n",
       "        [134217728,  43046721,         0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_exp = tensor_a ** tensor_b\n",
    "result_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000, 2.2361, 2.6458],\n",
       "        [2.8284, 3.0000, 0.0000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_sqrt = torch.sqrt(tensor_a)\n",
    "result_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3863, 1.6094, 1.9459],\n",
       "        [2.0794, 2.1972,   -inf]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_log = torch.log(tensor_a)  # natural logarithm (base e)\n",
    "result_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(33.),\n",
       " tensor([5.3333, 5.6667]),\n",
       " torch.return_types.max(\n",
       " values=tensor([8., 9., 7.]),\n",
       " indices=tensor([1, 1, 0])),\n",
       " torch.return_types.min(\n",
       " values=tensor([4., 0.]),\n",
       " indices=tensor([0, 2])))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a = tensor_a.type(torch.float32)\n",
    "total_sum = torch.sum(tensor_a)\n",
    "\n",
    "# Compute the mean along axis 1 (rows)\n",
    "mean_along_rows = torch.mean(tensor_a, dim=1)\n",
    "\n",
    "# Compute the maximum value along axis 0 (columns)\n",
    "max_along_columns = torch.max(tensor_a, dim=0)\n",
    "\n",
    "# Compute the minimum value along axis 1 (rows)\n",
    "min_along_rows = torch.min(tensor_a, dim=1)\n",
    "\n",
    "total_sum, mean_along_rows, max_along_columns, min_along_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting in PyTorch\n",
    "\n",
    "The key idea behind broadcasting is that the smaller tensor is \"broadcasted\" or expanded to match the shape of the larger one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broadcast results is: tensor([[ 6.,  7.,  9.],\n",
      "        [10., 11.,  2.]]) and of shape torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "scalar = 2\n",
    "result_broadcast = tensor_a + scalar\n",
    "print(f'broadcast results is: {result_broadcast} and of shape {result_broadcast.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two 2x2 tensors, tensor_a and tensor_b, and we want to concatenate them along dimension 0 to create a new tensor with a shape of 4x2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated tensor is: tensor([[2, 2],\n",
      "        [2, 2],\n",
      "        [4, 4],\n",
      "        [4, 4]]) and of shape torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor_a, tensor_b = torch.tensor([[2, 2], [2, 2]]), torch.tensor([[4, 4], [4, 4]])\n",
    "concatenated_tensor = torch.cat((tensor_a, tensor_b), dim=0)\n",
    "print(f'concatenated tensor is: {concatenated_tensor} and of shape {concatenated_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGrad and Gradients\n",
    "\n",
    "Autograd, short for Automatic Differentiation, is a key feature of PyTorch that allows for automatic computation of gradients (derivatives) of tensors. It is an essential component for training deep learning models through backpropagation.\n",
    "1. **Gradient Calculation** - In deep learning, we often need to compute gradients of a loss function with respect to model parameters. Autograd simplifies this process. When you perform operations on tensors that require gradients, PyTorch automatically tracks these operations and constructs a computation graph.\n",
    "\n",
    "2. **Computation Graph** - A computation graph is a directed acyclic graph (DAG) that represents the sequence of operations applied to tensors. Each operation in the graph is a node, and tensors flowing through these nodes are edges. The graph allows PyTorch to trace how input tensors influence the output tensors, which is crucial for gradient calculation.\n",
    "\n",
    "3. **Dynamic Computational Graph** - PyTorch uses a dynamic computation graph, which means the graph is built on-the-fly as operations are executed. This dynamic nature allows flexibility and is well-suited for models with varying architectures or inputs of different shapes.\n",
    "\n",
    "4. **Gradients** - Once you have a computation graph, you can compute gradients by backpropagating through the graph. Gradients represent how a small change in each input tensor would affect the final output. The gradients are computed using the chain rule of calculus, and they indicate the direction and magnitude of parameter updates during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([3.0, 2.0, 3.0], requires_grad=True)  # start tracking gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass. PyTorch records these operations in the computation graph\n",
    "y = x * 2\n",
    "z = y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward pass\n",
    "\n",
    "To compute gradients, initiate the backward pass using the backward() method on a scalar tensor (usually a loss)\n",
    "\n",
    "Chain Rule: backThe ward pass uses the chain rule of calculus to calculate the gradients. It starts from the final scalar value z and works backward through the computation graph to compute the gradients of intermediate tensors with respect to the target tensor (x in this case).\n",
    "\n",
    "It computes ∂z/∂y, which is the gradient of z with respect to y. Then, it computes ∂y/∂x, which is the gradient of y with respect to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the backward pass is stored in the .grad attribute of the tensors with requires_grad=True. In this case, x.grad will contain the gradient of z with respect to x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient with Autograd: 36.0\n",
      "This tensor does't have require gradients set to True\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with Autograd enabled (requires_grad=True)\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "\n",
    "# Perform some operations with Autograd enabled\n",
    "y = x * 3\n",
    "z = y ** 2\n",
    "w = z.mean()\n",
    "\n",
    "# Compute gradients while Autograd is enabled\n",
    "w.backward()\n",
    "\n",
    "# Access the gradient of x\n",
    "gradient_with_autograd = x.grad\n",
    "\n",
    "# Print the gradient\n",
    "print(\"Gradient with Autograd:\", gradient_with_autograd.item())\n",
    "\n",
    "\n",
    "# Now, let's turn Autograd off for a specific tensor\n",
    "x.requires_grad_(False)\n",
    "\n",
    "# Perform operations without Autograd (Autograd is off for x)\n",
    "y = x * 3\n",
    "z = y ** 2\n",
    "w = z.mean()\n",
    "try:\n",
    "    # Attempt to compute gradients \n",
    "    w.backward()\n",
    "except:\n",
    "    print(\"This tensor does't have require gradients set to True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Parameter\n",
    "\n",
    "In PyTorch, nn.Parameter is a class that is a subclass of the torch.Tensor class. It is specifically designed to be used as a container for tensors that should be considered parameters of a PyTorch nn.Module. Parameters are tensors that are meant to be learned during the training process, such as weights and biases in a neural network.\n",
    "\n",
    "Why nn.Parameter is useful?\n",
    "\n",
    "* Requires Grad Calculation: When you create a tensor using nn.Parameter, it is automatically registered as a parameter of the parent module, and PyTorch keeps track of it for gradient computation during backpropagation. This means that any operations involving these tensors will have gradients computed, allowing them to be updated during training using optimization techniques like stochastic gradient descent (SGD).\n",
    "* Initialization: Parameters created using nn.Parameter are typically initialized with random values (e.g., Gaussian or uniform distribution) by default. However, you can customize the initialization method if needed.\n",
    "* Access: You can easily access the parameters of a PyTorch module using the parameters() method, which returns an iterable containing all the nn.Parameter objects within the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3426,  0.2997,  0.0477,  0.9563, -0.8480],\n",
      "        [-2.2974, -1.8996,  0.8777,  0.4756, -1.2931],\n",
      "        [-0.3829,  0.3655, -0.4606, -2.3426,  0.7322],\n",
      "        [-0.0354,  0.4037, -0.9113,  1.4786,  0.5362],\n",
      "        [-0.0795,  0.3935,  1.7341, -0.0545,  0.2704],\n",
      "        [-1.1718,  0.6017, -0.2846, -0.2442,  1.0230],\n",
      "        [-0.8148,  0.9376,  0.7216, -1.5338,  0.6573],\n",
      "        [ 0.3531, -0.1765,  0.6951,  2.3895,  0.3509],\n",
      "        [-0.1698, -0.3017, -0.5952,  0.6879,  0.5409],\n",
      "        [-0.1112, -1.4798, -1.2071, -0.5397,  1.2772]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Create an nn.Parameter for weight and bias\n",
    "        self.weight = nn.Parameter(torch.randn(10, 5))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the parameters in the forward pass\n",
    "        z = torch.matmul(x, self.weight.t()) + self.bias\n",
    "        return z\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = MyModel()\n",
    "\n",
    "# Access and print the parameters\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Layer\n",
    "\n",
    "The Linear Layer in a PyTorch model receives input from every neuron of its preceding layer and performs matrix-vector multiplication\n",
    "\n",
    "![](./Linear.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 64)  # first linear layer\n",
    "        self.relu = nn.ReLU()          # activation function\n",
    "        self.fc2 = nn.Linear(64, 10)   # output layer for 10 classes\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MLP()\n",
    "input_tensor = torch.randn(32, 128)  # batch of 32 samples, input of 128 features\n",
    "output = model(input_tensor)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization (BatchNorm2d)\n",
    "\n",
    "Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1\n",
    "\n",
    "This is a data normalization layer in deep learning, used to normalize input data over a mini-packet in convolutional neural networks. It helps to stabilize and accelerate learning by improving the generalizing ability of the model\n",
    "\n",
    "![](./BatchNorm2d.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)  # BatchNorm after convolutional layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)  # Batch normalization\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = CNN()\n",
    "input_tensor = torch.randn(8, 3, 32, 32)  # batch of 8 images 3x32x32\n",
    "output = model(input_tensor)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "The Dropout layer randomly sets input units to 0 with a specified probability (rate) at each step during training time. This regularization technique helps prevent overfitting by reducing the reliance on specific neurons\n",
    "\n",
    "![](./Dropout.gif)\n",
    "\n",
    "No Dropout is applied during testing, but the output values are multiplied by (1 - p) to compensate for the scaling caused by the dropout during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # 50% of neurons will be deactivated\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Dropout usage\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleNN()\n",
    "input_tensor = torch.randn(32, 128)  # batch of 32 features & size of 128\n",
    "output = model(input_tensor)\n",
    "print(output.shape)  # output tensor with 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2d\n",
    "\n",
    "This is a convolutional layer used in neural networks for image processing. It applies learnable filters (kernels) to the input image to highlight features such as edges, textures, and objects\n",
    "\n",
    "The Conv2D layer in PyTorch creates a convolution kernel that is applied to the layer input to produce a tensor of outputs. It is a fundamental building block of convolutional neural networks (CNNs) used for tasks such as image classification and feature extraction\n",
    "\n",
    "![](./Conv2d.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # reduces the size of the feature map by 2 times\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleCNN()\n",
    "input_tensor = torch.randn(8, 3, 32, 32)\n",
    "output = model(input_tensor)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxPool2d\n",
    "\n",
    "The MaxPooling2D layer in PyTorch downsamples the input along its height and width by taking the maximum value over an input window. It is a common operation used in convolutional neural networks (CNNs) for reducing spatial dimensions while preserving important features\n",
    "\n",
    "![](./maxpool2d.png)\n",
    "\n",
    "Why is it useful ?\n",
    "* Reduces dimensionality by reducing the number of parameters\n",
    "* Filters noise, highlighting the most significant features\n",
    "* Makes the model resistant to small image shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AvgPool2d\n",
    "\n",
    "The AveragePooling2D layer in PyTorch downsamples the input along its height and width by taking the average value over an input window. It is a pooling operation commonly used in convolutional neural networks (CNNs) for reducing spatial dimensions while smoothing the features\n",
    "\n",
    "![](./avgpool2d.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "nn.AvgPool2d(\n",
    "    kernel_size,  # size of the pooling window, specified as a tuple (height, width)\n",
    "    stride=None,  # stride of the pooling operation along the height and width\n",
    "    padding=0  # \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "\n",
    "This is a recurrent layer used in neural networks to process sequential data such as text, audio signals, and time series. It processes the input data step by step, preserving the hidden state that is transmitted between time steps\n",
    "\n",
    "![](./rnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5087],\n",
       "        [0.1668],\n",
       "        [0.2136]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)  # linear layer for prediction\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, hidden = self.rnn(x)  # out: output on every step, hidden: last hidden state\n",
    "        out = self.fc(out[:, -1, :])  # last time series\n",
    "        return out\n",
    "\n",
    "\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 1    # one output (e. g. regression)\n",
    "seq_length = 5     # sequence length\n",
    "batch_size = 3     # sequences in batch\n",
    "\n",
    "model = RNN(input_size, hidden_size, output_size)\n",
    "input_tensor = torch.randn(batch_size, seq_length, input_size)\n",
    "output = model(input_tensor)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (long short-term memory)\n",
    "\n",
    "The Long Short-Term Memory (LSTM) layer in PyTorch is a type of RNN layer designed to capture long-range dependencies in sequential data. It uses a memory cell and gates to control the flow of information through the network.\n",
    "\n",
    "![](./lstm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1357],\n",
      "        [-0.1517],\n",
      "        [-0.3170]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h_n, c_n) = self.lstm(x)  # out: all outputs, h_n: las hidden state, c_n: memory\n",
    "        out = self.fc(out[:, -1, :])  # last time series\n",
    "        return out\n",
    "\n",
    "\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 1\n",
    "seq_length = 5\n",
    "batch_size = 3\n",
    "\n",
    "model = SimpleLSTM(input_size, hidden_size, output_size)\n",
    "input_tensor = torch.randn(batch_size, seq_length, input_size)\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n",
    "\n",
    "The Gated Recurrent Unit (GRU) layer in PyTorch is another type of RNN layer that is computationally efficient and can capture long-range dependencies. It uses update and reset gates to control information flow\n",
    "\n",
    "![](./gru.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2540],\n",
      "        [0.1755],\n",
      "        [0.0056]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(SimpleGRU, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, h_n = self.gru(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 1\n",
    "seq_length = 5\n",
    "batch_size = 3\n",
    "\n",
    "model = SimpleGRU(input_size, hidden_size, output_size)\n",
    "input_tensor = torch.randn(batch_size, seq_length, input_size)\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-head Attention\n",
    "\n",
    "Multi-Head Attention is a crucial component of transformer-based neural networks, such as the Transformer model and its variants (e.g., BERT, GPT). It enables the model to focus on different parts of the input sequence simultaneously, allowing it to capture complex relationships and dependencies within the data\n",
    "\n",
    "![](./attention%20block.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MultiheadAttention(\n",
    "    embed_dim,  # dimension of the input embeddings.\n",
    "    num_heads,  # number of attention heads. Each head attends to different parts of the input\n",
    "    dropout=0.0,  # If non-zero, applies dropout to the output of the attention layers (default is 0.0)\n",
    "    bias=True,  # If True, enables bias in the attention calculation (default is True)\n",
    "    add_bias_kv=False,  #  If True, adds bias to the key and value sequences (default is False)\n",
    "    add_zero_attn=False,  # If True, adds a learnable parameter to the attention calculation (default is False)\n",
    "    kdim=None,  # The dimension of the key vectors. By default, it's set to embed_dim\n",
    "    vdim=None  # The dimension of the value vectors. By default, it's set to embed_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 32])\n",
      "torch.Size([3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# attention parameters\n",
    "embed_dim = 32   # dimension of the input features\n",
    "num_heads = 4    # Number of heads of attention\n",
    "seq_length = 5\n",
    "batch_size = 3   # samples in batch\n",
    "\n",
    "# multi-head attention layer\n",
    "mha = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "\n",
    "# input data (query, key, value)\n",
    "query = torch.randn(batch_size, seq_length, embed_dim)\n",
    "key = torch.randn(batch_size, seq_length, embed_dim)\n",
    "value = torch.randn(batch_size, seq_length, embed_dim)\n",
    "\n",
    "# MultiheadAttention\n",
    "output, attention_weights = mha(query, key, value)\n",
    "\n",
    "print(output.shape)  # [batch_size, seq_len, embed_dim] → [3, 5, 32]\n",
    "print(attention_weights.shape)  # [batch_size, num_heads, seq_len, seq_len] → [3, 4, 5, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layer\n",
    "\n",
    "The Embedding Layer in PyTorch is used to create dense representations of categorical variables, commonly used in natural language processing tasks where words are converted into numerical vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "embedding_layer = nn.Embedding(\n",
    "    num_embeddings, embedding_dim, padding_idx=None,\n",
    "    max_norm=None, norm_type=2.0, scale_grad_by_freq=False,\n",
    "    sparse=False, _weight=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**num_embeddings**: Integer, the size of the vocabulary, i.e., the total number of unique categories\n",
    "\n",
    "**embedding_dim**: Integer, the dimension of the dense embedding\n",
    "\n",
    "**padding_idx**: Optional integer, indicating the padding index. If specified, the padding index will have a learned embedding with all zeros\n",
    "\n",
    "**max_norm**: Optional float, if specified, will normalize embeddings during forward pass to have a maximum norm of this value\n",
    "\n",
    "**norm_type**: Float, the type of norm to be applied when max_norm is specified (e.g., 2.0 for L2 norm)\n",
    "\n",
    "**scale_grad_by_freq**: Boolean, whether to scale gradients by the frequency of the words during training\n",
    "\n",
    "**sparse**: Boolean, indicating whether to use sparse gradients for embeddings\n",
    "\n",
    "**_weight**: Optional pre-trained embedding weights (a tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layer in PyTorch\n",
    "\n",
    "Custom layers in PyTorch allow you to define your own neural network components with custom behavior. We can create custom layers by subclassing nn.Module. Implement the __init__ method to set up any learnable parameters and other configuration options. Then, implement the forward method to define the forward pass logic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy\n",
    "\n",
    "\n",
    "class CustomLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(CustomLinear, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.randn(out_features))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.matmul(x, self.weight.t()) + self.bias\n",
    "        return out\n",
    "\n",
    "\n",
    "# Instantiate the custom linear layer\n",
    "custom_layer = CustomLinear(64, 32)  # Example: input size 64, output size 32\n",
    "\n",
    "# Example input data\n",
    "input_data = torch.randn(16, 64)\n",
    "\n",
    "# Use the custom layer\n",
    "output = custom_layer(input_data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation function\n",
    "\n",
    "Activation functions are essential components in neural networks that introduce non-linearity, allowing neural networks to model complex relationships in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid function\n",
    "\n",
    "Sigmoid is another common activation function that maps input values to the range [0, 1]. It is often used in binary classification problems where the output represents probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8808, 0.7311, 0.1192])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.tensor([2.0, 1.0, -2.0])\n",
    "\n",
    "# Define the Sigmoid activation function\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "# Apply Sigmoid to the input\n",
    "output = sigmoid(input_tensor)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "Softmax is used in multi-class classification problems to convert a vector of raw scores into a probability distribution over multiple classes. It exponentiates each score and normalizes them to sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "# Create a sample input tensor (raw scores)\n",
    "input_tensor = torch.tensor([2.0, 1.0, 0.1])\n",
    "\n",
    "# Define the Softmax activation function\n",
    "softmax = nn.Softmax(dim=0)\n",
    "\n",
    "# Apply Softmax to the input\n",
    "output = softmax(input_tensor)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU (Rectified Linear Activation)\n",
    "\n",
    "ReLU (Rectified Linear Unit) is one of the most commonly used activation functions in neural networks. It replaces all negative values in the input with zero and keeps positive values unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 2., 0., 3.])\n"
     ]
    }
   ],
   "source": [
    "# Create a sample input tensor\n",
    "input_tensor = torch.tensor([-1.0, 2.0, -0.5, 3.0])\n",
    "\n",
    "# Define the ReLU activation function\n",
    "relu = nn.ReLU()\n",
    "\n",
    "# Apply ReLU to the input\n",
    "output = relu(input_tensor)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Activation Function in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2689,  1.7616, -0.1888,  2.8577])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Activation(nn.Module):\n",
    "    def __init__(self, x):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        return self.x * torch.sigmoid(self.x)\n",
    "\n",
    "\n",
    "input_tensor = torch.tensor([-1.0, 2.0, -0.5, 3.0])\n",
    "function = Activation(input_tensor)\n",
    "function.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building models in PyTorch\n",
    "\n",
    "Steps to Create a Custom Model\n",
    "\n",
    "1) **Import Dependencies**: Import the necessary PyTorch modules and packages, such as torch.nn for defining neural network components.\n",
    "\n",
    "2) **Define the Model Class**: Create a custom Python class that inherits from nn.Module. This class will represent your neural network model. Define the network's architecture by adding layers and specifying their forward pass in the forward method.\n",
    "\n",
    "3) **Initialize Layers**: In the __init__ method of your custom model class, initialize the layers (e.g., convolutional layers, fully connected layers) that you'll use in your neural network.\n",
    "\n",
    "4) **Forward Pass**: Implement the forward pass in the forward method of your model class. This method defines how the input data passes through the layers of your model to produce an output.\n",
    "\n",
    "5) **Training and Optimization**: After defining your custom model, you can use it for training and optimization tasks. You'll need to define a loss function and choose an optimization algorithm (e.g., stochastic gradient descent) to train your model on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # fully connected MLP, 64 neurons for input and 10 for output\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more complex Convolutional Neural Network (CNN) model using PyTorch. This model is designed for image classification tasks and consists of both convolutional and fully connected layers\n",
    "\n",
    "The use of nn.Sequential allows us to group layers together in a sequential manner, making the code more concise and readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ComplexCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ComplexCNN, self).__init__()\n",
    "\n",
    "        # Sequential block for convolutional layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Sequential block for fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(256 * 4 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through convolutional layers\n",
    "        x = self.conv_layers(x)\n",
    "\n",
    "        # Flatten the feature maps\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Forward pass through fully connected layers\n",
    "        x = self.fc_layers(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Model Architecture with torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "              ReLU-2           [-1, 64, 32, 32]               0\n",
      "       BatchNorm2d-3           [-1, 64, 32, 32]             128\n",
      "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
      "            Conv2d-5          [-1, 128, 16, 16]          73,856\n",
      "              ReLU-6          [-1, 128, 16, 16]               0\n",
      "       BatchNorm2d-7          [-1, 128, 16, 16]             256\n",
      "         MaxPool2d-8            [-1, 128, 8, 8]               0\n",
      "            Conv2d-9            [-1, 256, 8, 8]         295,168\n",
      "             ReLU-10            [-1, 256, 8, 8]               0\n",
      "      BatchNorm2d-11            [-1, 256, 8, 8]             512\n",
      "        MaxPool2d-12            [-1, 256, 4, 4]               0\n",
      "           Linear-13                  [-1, 512]       2,097,664\n",
      "             ReLU-14                  [-1, 512]               0\n",
      "          Dropout-15                  [-1, 512]               0\n",
      "           Linear-16                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 2,470,402\n",
      "Trainable params: 2,470,402\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.86\n",
      "Params size (MB): 9.42\n",
      "Estimated Total Size (MB): 12.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "model = ComplexCNN(2)\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\n",
    "A callback is a mechanism in deep learning frameworks like PyTorch or TensorFlow that allows to customize and extend the behavior of a training process during training a neural network. It provides a way to specify certain actions to be taken at various points during training, such as at the end of an epoch or after each batch. Callbacks are often used for purposes like monitoring training progress, saving model checkpoints, applying learning rate schedules, early stopping, and more\n",
    "\n",
    "**Customizable Actions**: Callbacks enable you to define custom actions or functions that will be executed at specific points during training. For example, you can specify that you want to save the model's weights after each epoch or display training metrics periodically.\n",
    "\n",
    "**Modular and Reusable**: Callbacks are modular and reusable pieces of code. You can create your own custom callbacks to perform specific tasks tailored to your project's requirements.\n",
    "\n",
    "**Non-Intrusive**: Callbacks don't interfere with the core training loop of the deep learning framework. They complement the training process without altering the fundamental training algorithm.\n",
    "\n",
    "**Monitoring and Logging**: Callbacks are commonly used for monitoring training metrics such as loss, accuracy, or custom evaluation metrics. You can log these metrics to track how your model is performing over time.\n",
    "\n",
    "**Early Stopping**: One common use of callbacks is early stopping, where training is halted when a certain condition is met, such as when the validation loss stops improving, to prevent overfitting.\n",
    "\n",
    "**Model Checkpoint**s: You can use callbacks to save model checkpoints at specific intervals, ensuring that you can restore the model to a particular state if needed.\n",
    "\n",
    "**Learning Rate Scheduling**: Callbacks can be used to adjust the learning rate during training, enabling you to fine-tune the training process for better convergence.\n",
    "\n",
    "**TensorBoard Integration**: Callbacks can integrate with tools like TensorBoard for visualizing and analyzing training progress.\n",
    "\n",
    "**Callback Chains**: Multiple callbacks can be chained together to perform a sequence of actions during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start: initialization of the settings metric\n",
      "Epoch's start 1.\n",
      "  Batch 1 is done, loss = 1.6179\n",
      "  Batch 2 is done, loss = 1.2072\n",
      "  Batch 3 is done, loss = 1.6743\n",
      "  Batch 4 is done, loss = 0.7493\n",
      "  Batch 5 is done, loss = 0.7382\n",
      "Epoch 1 is done. Avg loss: 1.1974\n",
      "Epoch's start 2.\n",
      "  Batch 1 is done, loss = 1.4886\n",
      "  Batch 2 is done, loss = 1.0242\n",
      "  Batch 3 is done, loss = 1.6143\n",
      "  Batch 4 is done, loss = 0.6692\n",
      "  Batch 5 is done, loss = 0.6592\n",
      "Epoch 2 is done. Avg loss: 1.0911\n",
      "Epoch's start 3.\n",
      "  Batch 1 is done, loss = 1.3882\n",
      "  Batch 2 is done, loss = 0.8857\n",
      "  Batch 3 is done, loss = 1.5706\n",
      "  Batch 4 is done, loss = 0.6095\n",
      "  Batch 5 is done, loss = 0.6045\n",
      "Epoch 3 is done. Avg loss: 1.0117\n",
      "Epoch's start 4.\n",
      "  Batch 1 is done, loss = 1.3096\n",
      "  Batch 2 is done, loss = 0.7801\n",
      "  Batch 3 is done, loss = 1.5383\n",
      "  Batch 4 is done, loss = 0.5650\n",
      "  Batch 5 is done, loss = 0.5672\n",
      "Epoch 4 is done. Avg loss: 0.9520\n",
      "Epoch's start 5.\n",
      "  Batch 1 is done, loss = 1.2476\n",
      "  Batch 2 is done, loss = 0.6987\n",
      "  Batch 3 is done, loss = 1.5142\n",
      "  Batch 4 is done, loss = 0.5318\n",
      "  Batch 5 is done, loss = 0.5423\n",
      "Epoch 5 is done. Avg loss: 0.9069\n",
      "The end of training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# base callback class\n",
    "class Callback:\n",
    "    def on_train_begin(self, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        \n",
    "        # create learning history\n",
    "        logs['history'] = {'loss': []}\n",
    "        print(\"Training start: initialization of the settings metric\")\n",
    "\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "\n",
    "        # reset the counter for the current epoch\n",
    "        logs['epoch_loss'] = 0.0\n",
    "        logs['batches'] = 0\n",
    "        print(f\"Epoch's start {epoch+1}.\")\n",
    "\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "\n",
    "        logs['epoch_loss'] += logs.get('loss', 0.0)\n",
    "        logs['batches'] += 1  # update batches counter\n",
    "        # output an intermediate value for the current batch\n",
    "        print(f\"  Batch {batch+1} is done, loss = {logs.get('loss', 0.0):.4f}\")\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "\n",
    "        # calculate avg loss for epoch\n",
    "        avg_loss = logs['epoch_loss'] / logs['batches'] if logs['batches'] > 0 else float('nan')\n",
    "        # save to history\n",
    "        logs['history']['loss'].append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1} is done. Avg loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print(\"The end of training\")\n",
    "\n",
    "\n",
    "# certain callback class\n",
    "class MyLoggingCallback(Callback):\n",
    "    # anything can be changed, but base class already has all needed methods\n",
    "    pass\n",
    "\n",
    "\n",
    "# 100 samples, 10 features, predictor for regression\n",
    "X = torch.randn(100, 10)\n",
    "y = torch.randn(100, 1)\n",
    "\n",
    "# simple model with 1 layer\n",
    "model = nn.Linear(10, 1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# callback init. (lists can be sent)\n",
    "callbacks = [MyLoggingCallback()]\n",
    "\n",
    "logs = {}\n",
    "\n",
    "# epochs and batch size\n",
    "num_epochs = 5\n",
    "batch_size = 20\n",
    "num_batches = X.size(0) // batch_size\n",
    "\n",
    "\n",
    "# before training, set logs in callbacks\n",
    "for cb in callbacks:\n",
    "    cb.on_train_begin(logs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for cb in callbacks:\n",
    "        cb.on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    for batch in range(num_batches):\n",
    "        start = batch * batch_size\n",
    "        end = start + batch_size\n",
    "        inputs = X[start:end]\n",
    "        targets = y[start:end]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update logs for batch\n",
    "        batch_logs = {'loss': loss.item(), 'epoch_loss': 0, 'batches': 0}\n",
    "\n",
    "        for cb in callbacks:\n",
    "            cb.on_batch_end(batch, logs=batch_logs)\n",
    "\n",
    "        # accumulate the values for the epoch in the general logs dictionary\n",
    "        logs['epoch_loss'] = logs.get('epoch_loss', 0.0) + loss.item()\n",
    "        logs['batches'] = logs.get('batches', 0) + 1\n",
    "\n",
    "    for cb in callbacks:\n",
    "        cb.on_epoch_end(epoch, logs)\n",
    "        \n",
    "for cb in callbacks:\n",
    "    cb.on_train_end(logs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
