{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "PyTorch is a deep learning framework used for research and development in machine learning and artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor is a fundamental data structure that is similar to arrays or matrices. Tensors are the building blocks of neural networks and are used to represent data in the form of multi-dimensional arrays\n",
    "\n",
    "### Types of Tensors\n",
    "![](./Tensor.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.6731e-01,  4.1031e-01, -1.5540e-01,  ...,  2.0594e-01,\n",
       "          -7.7255e-01, -1.1984e-01],\n",
       "         [-5.6662e-01,  7.0067e-01, -3.4180e-01,  ..., -1.1127e+00,\n",
       "           1.8683e+00, -1.1175e+00],\n",
       "         [ 8.8551e-01, -6.9390e-01,  6.1661e-01,  ...,  9.9827e-01,\n",
       "           5.2346e-01,  1.1848e-01],\n",
       "         ...,\n",
       "         [-1.3863e+00, -1.5750e+00, -9.7003e-01,  ..., -2.8985e-01,\n",
       "           1.1005e+00, -3.1892e-01],\n",
       "         [-4.7203e-01, -2.4616e-01, -1.9265e+00,  ..., -7.0816e-01,\n",
       "          -5.6475e-01, -8.3122e-01],\n",
       "         [-1.1669e+00, -1.0620e-03, -1.9500e-02,  ...,  7.5206e-01,\n",
       "           1.8913e+00,  6.1879e-01]],\n",
       "\n",
       "        [[ 4.6298e-01,  5.4132e-01, -6.9952e-01,  ..., -4.9100e-01,\n",
       "          -7.0300e-01, -6.1826e-01],\n",
       "         [-8.0461e-01, -6.8585e-01, -5.3335e-01,  ..., -5.4940e-02,\n",
       "          -2.2417e-01, -9.4653e-01],\n",
       "         [ 1.5007e+00, -9.9051e-01,  1.6570e-02,  ..., -3.8530e-01,\n",
       "          -2.6853e-01, -4.9141e-01],\n",
       "         ...,\n",
       "         [ 8.4170e-01,  5.9050e-01,  1.0565e+00,  ...,  1.1243e+00,\n",
       "           2.5168e-01, -1.5642e+00],\n",
       "         [ 8.0263e-01, -1.9716e+00, -1.3334e+00,  ...,  2.2510e+00,\n",
       "           2.0635e-01, -2.1207e-01],\n",
       "         [ 6.3797e-01, -7.9496e-01, -2.5321e-01,  ..., -3.2946e-01,\n",
       "          -4.7364e-01, -2.7030e-01]],\n",
       "\n",
       "        [[-3.0399e-01,  1.5003e+00, -2.1852e-01,  ...,  5.6885e-02,\n",
       "           1.5649e+00, -5.1509e-01],\n",
       "         [ 4.6452e-01,  3.7256e-01,  3.8977e-01,  ..., -1.2080e+00,\n",
       "           1.0121e+00, -1.5772e+00],\n",
       "         [ 1.3017e-01, -9.8137e-01, -3.1028e-01,  ...,  7.8474e-01,\n",
       "          -3.5978e-02,  2.8495e-01],\n",
       "         ...,\n",
       "         [ 7.2386e-01,  2.1574e-02,  8.7633e-01,  ..., -5.2339e-01,\n",
       "          -1.3498e+00,  6.1217e-01],\n",
       "         [ 6.8984e-01,  3.0858e-01,  1.1412e+00,  ...,  1.8345e+00,\n",
       "          -9.4012e-01,  2.7153e+00],\n",
       "         [ 7.8942e-01, -3.3977e-01,  9.7477e-01,  ...,  1.6442e-01,\n",
       "          -3.7046e-02, -1.5791e+00]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(42.0)  # Creates a scalar tensor with the value 42.0. has 0 dimensions\n",
    "vector = torch.tensor([1, 2, 3, 4, 5])  # Creates a 1-D tensor with 5 elements\n",
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])  # Creates a 2-D tensor with 2 rows and 3 columns\n",
    "four_dim_tensor = torch.randn(32, 3, 64, 64)  # Create a 4-D tensor with shape (batch_size, channels, height, width)\n",
    "four_dim_tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different arguments can be provided for tensor creation:\n",
    "* Data\n",
    "* Dtype\n",
    "* Device (specify the device (CPU or GPU) on which the tensor should be located using this argument. If not provided, the tensor will be created on the CPU by default.)\n",
    "* Requires_grad (If set to True, the tensor will be set up to track operations on it for automatic differentiation (autograd) during backpropagation. This is useful for gradient-based optimization and training deep learning models.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor(data=[[1, 2, 3], [4, 5, 6]], \n",
    "dtype=torch.float32, \n",
    "device='cpu', \n",
    "requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor(data=[[1, 2, 3], [3, 2, 3]])\n",
    "tensor.type(torch.float32)\n",
    "tensor.numel()  # total elements in tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 3],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor = torch.reshape(tensor, (3, 2))\n",
    "reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 3],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor = torch.reshape(tensor, (-1, 2))  # -1 is used to infer one of dimensions\n",
    "reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1679, -0.4802,  0.6324,  ...,  0.7223, -0.5063, -0.7060],\n",
       "        [ 1.2336,  0.3826,  0.2796,  ..., -0.2616,  0.6765, -0.0804],\n",
       "        [-1.3299,  0.9156, -0.3471,  ...,  0.0298, -0.8025,  0.7965],\n",
       "        ...,\n",
       "        [ 0.9928, -0.0565, -0.2597,  ..., -0.2338,  0.4734,  0.0774],\n",
       "        [-0.2038, -0.8475, -1.2998,  ...,  2.0775,  0.3445,  0.5881],\n",
       "        [-0.6292, -2.4918,  1.1873,  ...,  0.4216,  2.0810,  1.0084]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(32, 3, 64, 64)\n",
    "x_flattened = x.view(x.size(0), -1)\n",
    "x_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_tensor = torch.unsqueeze(tensor, dim=0)  #  Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "expanded_tensor.size(), tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permute function\n",
    "The permute() function allows to rearrange dimensions in a tensor, providing with the flexibility to change the shape and orientation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted_tensor = tensor.permute(1, 0)  # Swap dimensions 0 and 1\n",
    "permuted_tensor.shape, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [3, 2, 3]]),\n",
       " tensor([[1, 3],\n",
       "         [2, 2],\n",
       "         [3, 3]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor, permuted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original tensor shape is: torch.Size([2, 3]),\n",
      "The transposed tensor using .t shape is: torch.Size([3, 2]),\n",
      "The transposed tensor using .tranpose shape is: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Transposing a Tensor (Swapping Rows and Columns)\n",
    "transposed_tensor_1 = tensor.t()\n",
    "transposed_tensor_2 = torch.transpose(tensor, 0, 1)  # Swap axes 0 and 1\n",
    "\n",
    "print(f'The original tensor shape is: {tensor.shape},\\n' \n",
    "      f'The transposed tensor using .t shape is: {transposed_tensor_1.shape},\\n' \n",
    "      f'The transposed tensor using .tranpose shape is: {transposed_tensor_2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition and subtraction between tensors same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9,  9, 10],\n",
       "        [17, 17,  7]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a = torch.tensor([[4, 5, 7], [8, 9, 0]])\n",
    "tensor_b = torch.tensor([[5, 4, 3], [9, 8, 7]])\n",
    "\n",
    "tensor_a + tensor_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1,  1,  4],\n",
       "        [-1,  1, -7]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a - tensor_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element-wise multiplication between 2 tensors of same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20, 20, 21],\n",
       "        [72, 72,  0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a * tensor_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix-wise multiplication (dot product) between 2 tensors where the inner dimensions match (the number of columns in the first tensor equals the number of rows in the second tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 72,  63,  54],\n",
       "        [121, 104,  87]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_c = torch.tensor([[5, 4, 3], [9, 8, 7], [1, 1, 1]])\n",
    "matmu = torch.matmul(tensor_a, tensor_c)\n",
    "matmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8000, 1.2500, 2.3333],\n",
       "        [0.8889, 1.1250, 0.0000]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div = tensor_a / tensor_b\n",
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     1024,       625,       343],\n",
       "        [134217728,  43046721,         0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_exp = tensor_a ** tensor_b\n",
    "result_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000, 2.2361, 2.6458],\n",
       "        [2.8284, 3.0000, 0.0000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_sqrt = torch.sqrt(tensor_a)\n",
    "result_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3863, 1.6094, 1.9459],\n",
       "        [2.0794, 2.1972,   -inf]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_log = torch.log(tensor_a)  # natural logarithm (base e)\n",
    "result_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(33.),\n",
       " tensor([5.3333, 5.6667]),\n",
       " torch.return_types.max(\n",
       " values=tensor([8., 9., 7.]),\n",
       " indices=tensor([1, 1, 0])),\n",
       " torch.return_types.min(\n",
       " values=tensor([4., 0.]),\n",
       " indices=tensor([0, 2])))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a = tensor_a.type(torch.float32)\n",
    "total_sum = torch.sum(tensor_a)\n",
    "\n",
    "# Compute the mean along axis 1 (rows)\n",
    "mean_along_rows = torch.mean(tensor_a, dim=1)\n",
    "\n",
    "# Compute the maximum value along axis 0 (columns)\n",
    "max_along_columns = torch.max(tensor_a, dim=0)\n",
    "\n",
    "# Compute the minimum value along axis 1 (rows)\n",
    "min_along_rows = torch.min(tensor_a, dim=1)\n",
    "\n",
    "total_sum, mean_along_rows, max_along_columns, min_along_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting in PyTorch\n",
    "\n",
    "The key idea behind broadcasting is that the smaller tensor is \"broadcasted\" or expanded to match the shape of the larger one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broadcast results is: tensor([[ 6.,  7.,  9.],\n",
      "        [10., 11.,  2.]]) and of shape torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "scalar = 2\n",
    "result_broadcast = tensor_a + scalar\n",
    "print(f'broadcast results is: {result_broadcast} and of shape {result_broadcast.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two 2x2 tensors, tensor_a and tensor_b, and we want to concatenate them along dimension 0 to create a new tensor with a shape of 4x2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated tensor is: tensor([[2, 2],\n",
      "        [2, 2],\n",
      "        [4, 4],\n",
      "        [4, 4]]) and of shape torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor_a, tensor_b = torch.tensor([[2, 2], [2, 2]]), torch.tensor([[4, 4], [4, 4]])\n",
    "concatenated_tensor = torch.cat((tensor_a, tensor_b), dim=0)\n",
    "print(f'concatenated tensor is: {concatenated_tensor} and of shape {concatenated_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGrad and Gradients\n",
    "\n",
    "Autograd, short for Automatic Differentiation, is a key feature of PyTorch that allows for automatic computation of gradients (derivatives) of tensors. It is an essential component for training deep learning models through backpropagation.\n",
    "1. **Gradient Calculation** - In deep learning, we often need to compute gradients of a loss function with respect to model parameters. Autograd simplifies this process. When you perform operations on tensors that require gradients, PyTorch automatically tracks these operations and constructs a computation graph.\n",
    "\n",
    "2. **Computation Graph** - A computation graph is a directed acyclic graph (DAG) that represents the sequence of operations applied to tensors. Each operation in the graph is a node, and tensors flowing through these nodes are edges. The graph allows PyTorch to trace how input tensors influence the output tensors, which is crucial for gradient calculation.\n",
    "\n",
    "3. **Dynamic Computational Graph** - PyTorch uses a dynamic computation graph, which means the graph is built on-the-fly as operations are executed. This dynamic nature allows flexibility and is well-suited for models with varying architectures or inputs of different shapes.\n",
    "\n",
    "4. **Gradients** - Once you have a computation graph, you can compute gradients by backpropagating through the graph. Gradients represent how a small change in each input tensor would affect the final output. The gradients are computed using the chain rule of calculus, and they indicate the direction and magnitude of parameter updates during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([3.0, 2.0, 3.0], requires_grad=True)  # start tracking gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass. PyTorch records these operations in the computation graph\n",
    "y = x * 2\n",
    "z = y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward pass\n",
    "\n",
    "To compute gradients, initiate the backward pass using the backward() method on a scalar tensor (usually a loss)\n",
    "\n",
    "Chain Rule: backThe ward pass uses the chain rule of calculus to calculate the gradients. It starts from the final scalar value z and works backward through the computation graph to compute the gradients of intermediate tensors with respect to the target tensor (x in this case).\n",
    "\n",
    "It computes ∂z/∂y, which is the gradient of z with respect to y. Then, it computes ∂y/∂x, which is the gradient of y with respect to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the backward pass is stored in the .grad attribute of the tensors with requires_grad=True. In this case, x.grad will contain the gradient of z with respect to x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient with Autograd: 36.0\n",
      "This tensor does't have require gradients set to True\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with Autograd enabled (requires_grad=True)\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "\n",
    "# Perform some operations with Autograd enabled\n",
    "y = x * 3\n",
    "z = y ** 2\n",
    "w = z.mean()\n",
    "\n",
    "# Compute gradients while Autograd is enabled\n",
    "w.backward()\n",
    "\n",
    "# Access the gradient of x\n",
    "gradient_with_autograd = x.grad\n",
    "\n",
    "# Print the gradient\n",
    "print(\"Gradient with Autograd:\", gradient_with_autograd.item())\n",
    "\n",
    "\n",
    "# Now, let's turn Autograd off for a specific tensor\n",
    "x.requires_grad_(False)\n",
    "\n",
    "# Perform operations without Autograd (Autograd is off for x)\n",
    "y = x * 3\n",
    "z = y ** 2\n",
    "w = z.mean()\n",
    "try:\n",
    "    # Attempt to compute gradients \n",
    "    w.backward()\n",
    "except:\n",
    "    print(\"This tensor does't have require gradients set to True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Parameter\n",
    "\n",
    "In PyTorch, nn.Parameter is a class that is a subclass of the torch.Tensor class. It is specifically designed to be used as a container for tensors that should be considered parameters of a PyTorch nn.Module. Parameters are tensors that are meant to be learned during the training process, such as weights and biases in a neural network.\n",
    "\n",
    "Why nn.Parameter is useful?\n",
    "\n",
    "* Requires Grad Calculation: When you create a tensor using nn.Parameter, it is automatically registered as a parameter of the parent module, and PyTorch keeps track of it for gradient computation during backpropagation. This means that any operations involving these tensors will have gradients computed, allowing them to be updated during training using optimization techniques like stochastic gradient descent (SGD).\n",
    "* Initialization: Parameters created using nn.Parameter are typically initialized with random values (e.g., Gaussian or uniform distribution) by default. However, you can customize the initialization method if needed.\n",
    "* Access: You can easily access the parameters of a PyTorch module using the parameters() method, which returns an iterable containing all the nn.Parameter objects within the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3426,  0.2997,  0.0477,  0.9563, -0.8480],\n",
      "        [-2.2974, -1.8996,  0.8777,  0.4756, -1.2931],\n",
      "        [-0.3829,  0.3655, -0.4606, -2.3426,  0.7322],\n",
      "        [-0.0354,  0.4037, -0.9113,  1.4786,  0.5362],\n",
      "        [-0.0795,  0.3935,  1.7341, -0.0545,  0.2704],\n",
      "        [-1.1718,  0.6017, -0.2846, -0.2442,  1.0230],\n",
      "        [-0.8148,  0.9376,  0.7216, -1.5338,  0.6573],\n",
      "        [ 0.3531, -0.1765,  0.6951,  2.3895,  0.3509],\n",
      "        [-0.1698, -0.3017, -0.5952,  0.6879,  0.5409],\n",
      "        [-0.1112, -1.4798, -1.2071, -0.5397,  1.2772]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Create an nn.Parameter for weight and bias\n",
    "        self.weight = nn.Parameter(torch.randn(10, 5))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the parameters in the forward pass\n",
    "        z = torch.matmul(x, self.weight.t()) + self.bias\n",
    "        return z\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = MyModel()\n",
    "\n",
    "# Access and print the parameters\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Layer\n",
    "\n",
    "The Linear Layer in a PyTorch model receives input from every neuron of its preceding layer and performs matrix-vector multiplication\n",
    "\n",
    "![](./Linear.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 64)  # first linear layer\n",
    "        self.relu = nn.ReLU()          # activation function\n",
    "        self.fc2 = nn.Linear(64, 10)   # output layer for 10 classes\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MLP()\n",
    "input_tensor = torch.randn(32, 128)  # batch of 32 samples, input of 128 features\n",
    "output = model(input_tensor)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization (BatchNorm2d)\n",
    "\n",
    "Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1\n",
    "\n",
    "This is a data normalization layer in deep learning, used to normalize input data over a mini-packet in convolutional neural networks. It helps to stabilize and accelerate learning by improving the generalizing ability of the model\n",
    "\n",
    "![](./BatchNorm2d.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)  # BatchNorm after convolutional layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)  # Batch normalization\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = CNN()\n",
    "input_tensor = torch.randn(8, 3, 32, 32)  # batch of 8 images 3x32x32\n",
    "output = model(input_tensor)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "The Dropout layer randomly sets input units to 0 with a specified probability (rate) at each step during training time. This regularization technique helps prevent overfitting by reducing the reliance on specific neurons\n",
    "\n",
    "![](./Dropout.gif)\n",
    "\n",
    "No Dropout is applied during testing, but the output values are multiplied by (1 - p) to compensate for the scaling caused by the dropout during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # 50% of neurons will be deactivated\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Dropout usage\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleNN()\n",
    "input_tensor = torch.randn(32, 128)  # batch of 32 features & size of 128\n",
    "output = model(input_tensor)\n",
    "print(output.shape)  # output tensor with 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2d\n",
    "\n",
    "This is a convolutional layer used in neural networks for image processing. It applies learnable filters (kernels) to the input image to highlight features such as edges, textures, and objects\n",
    "\n",
    "The Conv2D layer in PyTorch creates a convolution kernel that is applied to the layer input to produce a tensor of outputs. It is a fundamental building block of convolutional neural networks (CNNs) used for tasks such as image classification and feature extraction\n",
    "\n",
    "![](./Conv2d.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # reduces the size of the feature map by 2 times\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SimpleCNN()\n",
    "input_tensor = torch.randn(8, 3, 32, 32)\n",
    "output = model(input_tensor)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxPool2d\n",
    "\n",
    "The MaxPooling2D layer in PyTorch downsamples the input along its height and width by taking the maximum value over an input window. It is a common operation used in convolutional neural networks (CNNs) for reducing spatial dimensions while preserving important features\n",
    "\n",
    "![](./maxpool2d.png)\n",
    "\n",
    "Why is it useful ?\n",
    "* Reduces dimensionality by reducing the number of parameters\n",
    "* Filters noise, highlighting the most significant features\n",
    "* Makes the model resistant to small image shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AvgPool2d\n",
    "\n",
    "The AveragePooling2D layer in PyTorch downsamples the input along its height and width by taking the average value over an input window. It is a pooling operation commonly used in convolutional neural networks (CNNs) for reducing spatial dimensions while smoothing the features\n",
    "\n",
    "![](./avgpool2d.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "nn.AvgPool2d(\n",
    "    kernel_size,  # size of the pooling window, specified as a tuple (height, width)\n",
    "    stride=None,  # stride of the pooling operation along the height and width\n",
    "    padding=0  # \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "\n",
    "This is a recurrent layer used in neural networks to process sequential data such as text, audio signals, and time series. It processes the input data step by step, preserving the hidden state that is transmitted between time steps\n",
    "\n",
    "![](./rnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5087],\n",
       "        [0.1668],\n",
       "        [0.2136]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)  # linear layer for prediction\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, hidden = self.rnn(x)  # out: output on every step, hidden: last hidden state\n",
    "        out = self.fc(out[:, -1, :])  # last time series\n",
    "        return out\n",
    "\n",
    "\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 1    # one output (e. g. regression)\n",
    "seq_length = 5     # sequence length\n",
    "batch_size = 3     # sequences in batch\n",
    "\n",
    "model = RNN(input_size, hidden_size, output_size)\n",
    "input_tensor = torch.randn(batch_size, seq_length, input_size)\n",
    "output = model(input_tensor)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (long short-term memory)\n",
    "\n",
    "The Long Short-Term Memory (LSTM) layer in PyTorch is a type of RNN layer designed to capture long-range dependencies in sequential data. It uses a memory cell and gates to control the flow of information through the network.\n",
    "\n",
    "![](./lstm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1357],\n",
      "        [-0.1517],\n",
      "        [-0.3170]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h_n, c_n) = self.lstm(x)  # out: all outputs, h_n: las hidden state, c_n: memory\n",
    "        out = self.fc(out[:, -1, :])  # last time series\n",
    "        return out\n",
    "\n",
    "\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 1\n",
    "seq_length = 5\n",
    "batch_size = 3\n",
    "\n",
    "model = SimpleLSTM(input_size, hidden_size, output_size)\n",
    "input_tensor = torch.randn(batch_size, seq_length, input_size)\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n",
    "\n",
    "The Gated Recurrent Unit (GRU) layer in PyTorch is another type of RNN layer that is computationally efficient and can capture long-range dependencies. It uses update and reset gates to control information flow\n",
    "\n",
    "![](./gru.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2540],\n",
      "        [0.1755],\n",
      "        [0.0056]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(SimpleGRU, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, h_n = self.gru(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 1\n",
    "seq_length = 5\n",
    "batch_size = 3\n",
    "\n",
    "model = SimpleGRU(input_size, hidden_size, output_size)\n",
    "input_tensor = torch.randn(batch_size, seq_length, input_size)\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-head Attention\n",
    "\n",
    "Multi-Head Attention is a crucial component of transformer-based neural networks, such as the Transformer model and its variants (e.g., BERT, GPT). It enables the model to focus on different parts of the input sequence simultaneously, allowing it to capture complex relationships and dependencies within the data\n",
    "\n",
    "![](./attention%20block.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MultiheadAttention(\n",
    "    embed_dim,  # dimension of the input embeddings.\n",
    "    num_heads,  # number of attention heads. Each head attends to different parts of the input\n",
    "    dropout=0.0,  # If non-zero, applies dropout to the output of the attention layers (default is 0.0)\n",
    "    bias=True,  # If True, enables bias in the attention calculation (default is True)\n",
    "    add_bias_kv=False,  #  If True, adds bias to the key and value sequences (default is False)\n",
    "    add_zero_attn=False,  # If True, adds a learnable parameter to the attention calculation (default is False)\n",
    "    kdim=None,  # The dimension of the key vectors. By default, it's set to embed_dim\n",
    "    vdim=None  # The dimension of the value vectors. By default, it's set to embed_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 32])\n",
      "torch.Size([3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# attention parameters\n",
    "embed_dim = 32   # dimension of the input features\n",
    "num_heads = 4    # Number of heads of attention\n",
    "seq_length = 5\n",
    "batch_size = 3   # samples in batch\n",
    "\n",
    "# multi-head attention layer\n",
    "mha = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "\n",
    "# input data (query, key, value)\n",
    "query = torch.randn(batch_size, seq_length, embed_dim)\n",
    "key = torch.randn(batch_size, seq_length, embed_dim)\n",
    "value = torch.randn(batch_size, seq_length, embed_dim)\n",
    "\n",
    "# MultiheadAttention\n",
    "output, attention_weights = mha(query, key, value)\n",
    "\n",
    "print(output.shape)  # [batch_size, seq_len, embed_dim] → [3, 5, 32]\n",
    "print(attention_weights.shape)  # [batch_size, num_heads, seq_len, seq_len] → [3, 4, 5, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layer\n",
    "\n",
    "The Embedding Layer in PyTorch is used to create dense representations of categorical variables, commonly used in natural language processing tasks where words are converted into numerical vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "embedding_layer = nn.Embedding(\n",
    "    num_embeddings, embedding_dim, padding_idx=None,\n",
    "    max_norm=None, norm_type=2.0, scale_grad_by_freq=False,\n",
    "    sparse=False, _weight=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**num_embeddings**: Integer, the size of the vocabulary, i.e., the total number of unique categories\n",
    "\n",
    "**embedding_dim**: Integer, the dimension of the dense embedding\n",
    "\n",
    "**padding_idx**: Optional integer, indicating the padding index. If specified, the padding index will have a learned embedding with all zeros\n",
    "\n",
    "**max_norm**: Optional float, if specified, will normalize embeddings during forward pass to have a maximum norm of this value\n",
    "\n",
    "**norm_type**: Float, the type of norm to be applied when max_norm is specified (e.g., 2.0 for L2 norm)\n",
    "\n",
    "**scale_grad_by_freq**: Boolean, whether to scale gradients by the frequency of the words during training\n",
    "\n",
    "**sparse**: Boolean, indicating whether to use sparse gradients for embeddings\n",
    "\n",
    "**_weight**: Optional pre-trained embedding weights (a tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layer in PyTorch\n",
    "\n",
    "Custom layers in PyTorch allow you to define your own neural network components with custom behavior. We can create custom layers by subclassing nn.Module. Implement the __init__ method to set up any learnable parameters and other configuration options. Then, implement the forward method to define the forward pass logic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy\n",
    "\n",
    "\n",
    "class CustomLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(CustomLinear, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.randn(out_features))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.matmul(x, self.weight.t()) + self.bias\n",
    "        return out\n",
    "\n",
    "\n",
    "# Instantiate the custom linear layer\n",
    "custom_layer = CustomLinear(64, 32)  # Example: input size 64, output size 32\n",
    "\n",
    "# Example input data\n",
    "input_data = torch.randn(16, 64)\n",
    "\n",
    "# Use the custom layer\n",
    "output = custom_layer(input_data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation function\n",
    "\n",
    "Activation functions are essential components in neural networks that introduce non-linearity, allowing neural networks to model complex relationships in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid function\n",
    "\n",
    "Sigmoid is another common activation function that maps input values to the range [0, 1]. It is often used in binary classification problems where the output represents probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8808, 0.7311, 0.1192])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.tensor([2.0, 1.0, -2.0])\n",
    "\n",
    "# Define the Sigmoid activation function\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "# Apply Sigmoid to the input\n",
    "output = sigmoid(input_tensor)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "Softmax is used in multi-class classification problems to convert a vector of raw scores into a probability distribution over multiple classes. It exponentiates each score and normalizes them to sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "# Create a sample input tensor (raw scores)\n",
    "input_tensor = torch.tensor([2.0, 1.0, 0.1])\n",
    "\n",
    "# Define the Softmax activation function\n",
    "softmax = nn.Softmax(dim=0)\n",
    "\n",
    "# Apply Softmax to the input\n",
    "output = softmax(input_tensor)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU (Rectified Linear Activation)\n",
    "\n",
    "ReLU (Rectified Linear Unit) is one of the most commonly used activation functions in neural networks. It replaces all negative values in the input with zero and keeps positive values unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 2., 0., 3.])\n"
     ]
    }
   ],
   "source": [
    "# Create a sample input tensor\n",
    "input_tensor = torch.tensor([-1.0, 2.0, -0.5, 3.0])\n",
    "\n",
    "# Define the ReLU activation function\n",
    "relu = nn.ReLU()\n",
    "\n",
    "# Apply ReLU to the input\n",
    "output = relu(input_tensor)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Activation Function in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2689,  1.7616, -0.1888,  2.8577])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Activation(nn.Module):\n",
    "    def __init__(self, x):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        return self.x * torch.sigmoid(self.x)\n",
    "\n",
    "\n",
    "input_tensor = torch.tensor([-1.0, 2.0, -0.5, 3.0])\n",
    "function = Activation(input_tensor)\n",
    "function.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building models in PyTorch\n",
    "\n",
    "Steps to Create a Custom Model\n",
    "\n",
    "1) **Import Dependencies**: Import the necessary PyTorch modules and packages, such as torch.nn for defining neural network components.\n",
    "\n",
    "2) **Define the Model Class**: Create a custom Python class that inherits from nn.Module. This class will represent your neural network model. Define the network's architecture by adding layers and specifying their forward pass in the forward method.\n",
    "\n",
    "3) **Initialize Layers**: In the __init__ method of your custom model class, initialize the layers (e.g., convolutional layers, fully connected layers) that you'll use in your neural network.\n",
    "\n",
    "4) **Forward Pass**: Implement the forward pass in the forward method of your model class. This method defines how the input data passes through the layers of your model to produce an output.\n",
    "\n",
    "5) **Training and Optimization**: After defining your custom model, you can use it for training and optimization tasks. You'll need to define a loss function and choose an optimization algorithm (e.g., stochastic gradient descent) to train your model on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # fully connected MLP, 64 neurons for input and 10 for output\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more complex Convolutional Neural Network (CNN) model using PyTorch. This model is designed for image classification tasks and consists of both convolutional and fully connected layers\n",
    "\n",
    "The use of nn.Sequential allows us to group layers together in a sequential manner, making the code more concise and readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ComplexCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ComplexCNN, self).__init__()\n",
    "\n",
    "        # Sequential block for convolutional layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Sequential block for fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(256 * 4 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through convolutional layers\n",
    "        x = self.conv_layers(x)\n",
    "\n",
    "        # Flatten the feature maps\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Forward pass through fully connected layers\n",
    "        x = self.fc_layers(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Model Architecture with torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "              ReLU-2           [-1, 64, 32, 32]               0\n",
      "       BatchNorm2d-3           [-1, 64, 32, 32]             128\n",
      "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
      "            Conv2d-5          [-1, 128, 16, 16]          73,856\n",
      "              ReLU-6          [-1, 128, 16, 16]               0\n",
      "       BatchNorm2d-7          [-1, 128, 16, 16]             256\n",
      "         MaxPool2d-8            [-1, 128, 8, 8]               0\n",
      "            Conv2d-9            [-1, 256, 8, 8]         295,168\n",
      "             ReLU-10            [-1, 256, 8, 8]               0\n",
      "      BatchNorm2d-11            [-1, 256, 8, 8]             512\n",
      "        MaxPool2d-12            [-1, 256, 4, 4]               0\n",
      "           Linear-13                  [-1, 512]       2,097,664\n",
      "             ReLU-14                  [-1, 512]               0\n",
      "          Dropout-15                  [-1, 512]               0\n",
      "           Linear-16                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 2,470,402\n",
      "Trainable params: 2,470,402\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.86\n",
      "Params size (MB): 9.42\n",
      "Estimated Total Size (MB): 12.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "model = ComplexCNN(2)\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\n",
    "A callback is a mechanism in deep learning frameworks like PyTorch or TensorFlow that allows to customize and extend the behavior of a training process during training a neural network. It provides a way to specify certain actions to be taken at various points during training, such as at the end of an epoch or after each batch. Callbacks are often used for purposes like monitoring training progress, saving model checkpoints, applying learning rate schedules, early stopping, and more\n",
    "\n",
    "**Customizable Actions**: Callbacks enable you to define custom actions or functions that will be executed at specific points during training. For example, you can specify that you want to save the model's weights after each epoch or display training metrics periodically.\n",
    "\n",
    "**Modular and Reusable**: Callbacks are modular and reusable pieces of code. You can create your own custom callbacks to perform specific tasks tailored to your project's requirements.\n",
    "\n",
    "**Non-Intrusive**: Callbacks don't interfere with the core training loop of the deep learning framework. They complement the training process without altering the fundamental training algorithm.\n",
    "\n",
    "**Monitoring and Logging**: Callbacks are commonly used for monitoring training metrics such as loss, accuracy, or custom evaluation metrics. You can log these metrics to track how your model is performing over time.\n",
    "\n",
    "**Early Stopping**: One common use of callbacks is early stopping, where training is halted when a certain condition is met, such as when the validation loss stops improving, to prevent overfitting.\n",
    "\n",
    "**Model Checkpoint**s: You can use callbacks to save model checkpoints at specific intervals, ensuring that you can restore the model to a particular state if needed.\n",
    "\n",
    "**Learning Rate Scheduling**: Callbacks can be used to adjust the learning rate during training, enabling you to fine-tune the training process for better convergence.\n",
    "\n",
    "**TensorBoard Integration**: Callbacks can integrate with tools like TensorBoard for visualizing and analyzing training progress.\n",
    "\n",
    "**Callback Chains**: Multiple callbacks can be chained together to perform a sequence of actions during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start: initialization of the settings metric\n",
      "Epoch's start 1.\n",
      "  Batch 1 is done, loss = 1.6179\n",
      "  Batch 2 is done, loss = 1.2072\n",
      "  Batch 3 is done, loss = 1.6743\n",
      "  Batch 4 is done, loss = 0.7493\n",
      "  Batch 5 is done, loss = 0.7382\n",
      "Epoch 1 is done. Avg loss: 1.1974\n",
      "Epoch's start 2.\n",
      "  Batch 1 is done, loss = 1.4886\n",
      "  Batch 2 is done, loss = 1.0242\n",
      "  Batch 3 is done, loss = 1.6143\n",
      "  Batch 4 is done, loss = 0.6692\n",
      "  Batch 5 is done, loss = 0.6592\n",
      "Epoch 2 is done. Avg loss: 1.0911\n",
      "Epoch's start 3.\n",
      "  Batch 1 is done, loss = 1.3882\n",
      "  Batch 2 is done, loss = 0.8857\n",
      "  Batch 3 is done, loss = 1.5706\n",
      "  Batch 4 is done, loss = 0.6095\n",
      "  Batch 5 is done, loss = 0.6045\n",
      "Epoch 3 is done. Avg loss: 1.0117\n",
      "Epoch's start 4.\n",
      "  Batch 1 is done, loss = 1.3096\n",
      "  Batch 2 is done, loss = 0.7801\n",
      "  Batch 3 is done, loss = 1.5383\n",
      "  Batch 4 is done, loss = 0.5650\n",
      "  Batch 5 is done, loss = 0.5672\n",
      "Epoch 4 is done. Avg loss: 0.9520\n",
      "Epoch's start 5.\n",
      "  Batch 1 is done, loss = 1.2476\n",
      "  Batch 2 is done, loss = 0.6987\n",
      "  Batch 3 is done, loss = 1.5142\n",
      "  Batch 4 is done, loss = 0.5318\n",
      "  Batch 5 is done, loss = 0.5423\n",
      "Epoch 5 is done. Avg loss: 0.9069\n",
      "The end of training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# base callback class\n",
    "class Callback:\n",
    "    def on_train_begin(self, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        \n",
    "        # create learning history\n",
    "        logs['history'] = {'loss': []}\n",
    "        print(\"Training start: initialization of the settings metric\")\n",
    "\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "\n",
    "        # reset the counter for the current epoch\n",
    "        logs['epoch_loss'] = 0.0\n",
    "        logs['batches'] = 0\n",
    "        print(f\"Epoch's start {epoch+1}.\")\n",
    "\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "\n",
    "        logs['epoch_loss'] += logs.get('loss', 0.0)\n",
    "        logs['batches'] += 1  # update batches counter\n",
    "        # output an intermediate value for the current batch\n",
    "        print(f\"  Batch {batch+1} is done, loss = {logs.get('loss', 0.0):.4f}\")\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "\n",
    "        # calculate avg loss for epoch\n",
    "        avg_loss = logs['epoch_loss'] / logs['batches'] if logs['batches'] > 0 else float('nan')\n",
    "        # save to history\n",
    "        logs['history']['loss'].append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1} is done. Avg loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print(\"The end of training\")\n",
    "\n",
    "\n",
    "# certain callback class\n",
    "class MyLoggingCallback(Callback):\n",
    "    # anything can be changed, but base class already has all needed methods\n",
    "    pass\n",
    "\n",
    "\n",
    "# 100 samples, 10 features, predictor for regression\n",
    "X = torch.randn(100, 10)\n",
    "y = torch.randn(100, 1)\n",
    "\n",
    "# simple model with 1 layer\n",
    "model = nn.Linear(10, 1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# callback init. (lists can be sent)\n",
    "callbacks = [MyLoggingCallback()]\n",
    "\n",
    "logs = {}\n",
    "\n",
    "# epochs and batch size\n",
    "num_epochs = 5\n",
    "batch_size = 20\n",
    "num_batches = X.size(0) // batch_size\n",
    "\n",
    "\n",
    "# before training, set logs in callbacks\n",
    "for cb in callbacks:\n",
    "    cb.on_train_begin(logs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for cb in callbacks:\n",
    "        cb.on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    for batch in range(num_batches):\n",
    "        start = batch * batch_size\n",
    "        end = start + batch_size\n",
    "        inputs = X[start:end]\n",
    "        targets = y[start:end]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update logs for batch\n",
    "        batch_logs = {'loss': loss.item(), 'epoch_loss': 0, 'batches': 0}\n",
    "\n",
    "        for cb in callbacks:\n",
    "            cb.on_batch_end(batch, logs=batch_logs)\n",
    "\n",
    "        # accumulate the values for the epoch in the general logs dictionary\n",
    "        logs['epoch_loss'] = logs.get('epoch_loss', 0.0) + loss.item()\n",
    "        logs['batches'] = logs.get('batches', 0) + 1\n",
    "\n",
    "    for cb in callbacks:\n",
    "        cb.on_epoch_end(epoch, logs)\n",
    "        \n",
    "for cb in callbacks:\n",
    "    cb.on_train_end(logs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard\n",
    "\n",
    "TensorBoard is a powerful visualization tool primarily associated with TensorFlow. However, we can use the TensorBoardX library to achieve similar functionality in PyTorch. This callback logs events for TensorBoardX, enabling you to visualize and monitor your PyTorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# Create a SummaryWriter for TensorBoard\n",
    "writer = SummaryWriter(log_dir=\"logs\")\n",
    "\n",
    "# Inside training loop or callback\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Add scalars to TensorBoard\n",
    "    writer.add_scalar(\"Loss\", loss, global_step=batch_num)\n",
    "    writer.add_scalar(\"Accuracy\", accuracy, global_step=batch_num)\n",
    "\n",
    "# Close the SummaryWriter when done\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduler\n",
    "A Learning Rate Scheduler is a callback that dynamically adjusts the learning rate during training to improve model convergence. In PyTorch, you can easily set up a Learning Rate Scheduler using built-in scheduler classes like StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Create an optimizer (e.g., SGD or Adam)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Define a learning rate scheduler using StepLR\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Inside your training loop or callback\n",
    "for epoch in range(num_epochs):\n",
    "    # ... Training code ...\n",
    "\n",
    "    # Update the learning rate using the scheduler\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "\n",
    "A loss function serves as a tool for assessing the difference between the predicted output and the actual target (ground truth) for a given set of input data. The purpose of a loss function is to provide a measure of how well or poorly a machine learning model is performing on a specific task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Entropy Loss (Log Loss)\n",
    "\n",
    "Cross-Entropy Loss, also known as Log Loss, is a common loss function used in classification problems, especially when dealing with multiple classes. It measures the dissimilarity between predicted class probabilities and the true class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the Cross-Entropy Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Inside your training loop or forward pass\n",
    "output = model(input)\n",
    "loss = criterion(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the Mean Squared Error Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Inside your training loop or forward pass\n",
    "output = model(input)\n",
    "loss = criterion(output, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Cross-Entropy Loss\n",
    "\n",
    "Binary Cross-Entropy Loss is used in binary classification problems to measure the dissimilarity between predicted binary class probabilities and true binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the Binary Cross-Entropy Loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Inside your training loop or forward pass\n",
    "output = model(input)\n",
    "loss = criterion(output, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "Optimizers are algorithms or techniques used to adjust the parameters of a model in order to minimize the loss function. The main goal of an optimizer is to find the best set of model parameters that result in the lowest possible value of the loss function\n",
    "\n",
    "**How Optimizers Work**:\n",
    "* Forward Pass: During the forward pass, the model computes predictions given the input data\n",
    "* Loss Calculation: The loss function quantifies the difference between the model's predictions and the ground truth\n",
    "* Backpropagation: PyTorch automatically computes gradients of the loss with respect to model parameters using the backward pass\n",
    "* Optimizer Step: The optimizer updates model parameters using the computed gradients, effectively adjusting them to minimize the loss\n",
    "\n",
    "**Training Loop Example**\n",
    "1) In each training iteration, the model performs a forward pass to make predictions\n",
    "2) The loss is computed based on the predictions and ground truth\n",
    "3) The optimizer's zero_grad() method is used to clear previous gradients\n",
    "4) Backpropagation computes gradients of the loss with respect to model parameters\n",
    "5) The optimizer's step() method updates the model parameters using the computed gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_data in dataloader:\n",
    "        # Forward Pass\n",
    "        outputs = model(batch_data)\n",
    "\n",
    "        # Calculate Loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer Step\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "\n",
    "SGD is the most basic optimizer. It updates model parameters by computing the gradients of the loss with respect to the parameters and moving in the direction that reduces the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSprop\n",
    "\n",
    "RMSprop adjusts the learning rates for each parameter based on a moving average of the squared gradients. It helps stabilize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam\n",
    "\n",
    "Adam combines the benefits of both the AdaGrad and RMSprop optimizers. It adapts the learning rates for each parameter individually based on the history of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom optimizer\n",
    "\n",
    "Custom optimizers are implemented as Python classes that inherit from the base torch.optim.Optimizer class\n",
    "\n",
    "Here are the general steps to create a custom optimizer in PyTorch:\n",
    "\n",
    "* Define Your Custom Optimizer Class: Create a Python class that inherits from Optimizer. This class will contain the optimization logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomOptimizer(torch.nn.Optimizer):\n",
    "    def __init__(self, params, lr=0.01, **kwargs):\n",
    "        super(MyCustomOptimizer, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        # Implement the optimization step here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructor (__init__ Method): Inside your custom optimizer class, define the constructor (__init__) method to accept the following parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Params: An iterable of parameters to optimize or dictionaries defining parameter groups.\n",
    "* Other hyperparameters (e.g., learning rate and any custom hyperparameters) as keyword arguments.\n",
    "* Call the superclass constructor to set up the optimizer's initial state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step Method**: Implement the step method, which is responsible for performing a single optimization step. Inside this method, you should update the model's parameters based on the gradients computed during the forward and backward passes. You can access the parameter values, gradients, and other optimizer-specific parameters within this method.\n",
    "\n",
    "**Optional Methods**: Depending on your custom optimizer's requirements, you might also need to implement other methods like __setstate__ for handling saved state when loading models. These methods are optional and depend on the specific needs of your custom optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccSGD(torch.nn.Optimizer):\n",
    "    r\"\"\"\n",
    "    Args:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float): learning rate (required)\n",
    "        kappa (float, optional): ratio of long to short step (default: 1000)\n",
    "        xi (float, optional): statistical advantage parameter (default: 10)\n",
    "        smallConst (float, optional): any value <=1 (default: 0.7)\n",
    "    Example:\n",
    "        >>> from AccSGD import *\n",
    "        >>> optimizer = AccSGD(model.parameters(), lr=0.1, kappa = 1000.0, xi = 10.0)\n",
    "        >>> optimizer.zero_grad()\n",
    "        >>> loss_fn(model(input), target).backward()\n",
    "        >>> optimizer.step()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=required, kappa = 1000.0, xi = 10.0, smallConst = 0.7, weight_decay=0):\n",
    "        defaults = dict(lr=lr, kappa=kappa, xi=xi, smallConst=smallConst,\n",
    "                        weight_decay=weight_decay)\n",
    "        super(AccSGD, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(AccSGD, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \"\"\" Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group['weight_decay']\n",
    "            large_lr = (group['lr']*group['kappa'])/(group['smallConst'])\n",
    "            Alpha = 1.0 - ((group['smallConst']*group['smallConst']*group['xi'])/group['kappa'])\n",
    "            Beta = 1.0 - Alpha\n",
    "            zeta = group['smallConst']/(group['smallConst']+Beta)\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "                if weight_decay != 0:\n",
    "                    d_p.add_(weight_decay, p.data)\n",
    "                param_state = self.state[p]\n",
    "                if 'momentum_buffer' not in param_state:\n",
    "                    param_state['momentum_buffer'] = copy.deepcopy(p.data)\n",
    "                buf = param_state['momentum_buffer']\n",
    "                buf.mul_((1.0/Beta)-1.0)\n",
    "                buf.add_(-large_lr,d_p)\n",
    "                buf.add_(p.data)\n",
    "                buf.mul_(Beta)\n",
    "\n",
    "                p.data.add_(-group['lr'],d_p)\n",
    "                p.data.mul_(zeta)\n",
    "                p.data.add_(1.0-zeta,buf)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets processing using pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All datasets are subclasses of torch.utils.data.Dataset i.e, they have __getitem__ and __len__ methods implemented. Hence, they can all be passed to a torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "\n",
    "imagenet_data = torchvision.datasets.ImageNet('path/to/imagenet_root/')\n",
    "data_loader = torch.utils.data.DataLoader(imagenet_data,\n",
    "                                          batch_size=4,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset from Folder using ImageFolder\n",
    "ImageFolder is a class provided by the PyTorch library, which is commonly used for handling image datasets. It's a part of the torchvision.datasets module, specifically designed for loading image data in a format that is suitable for training deep learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset/\n",
    "\n",
    "├── class1/\n",
    "\n",
    "│   ├── image1.jpg\n",
    "\n",
    "│   ├── image2.jpg\n",
    "\n",
    "│   ├── ...\n",
    "\n",
    "├── class2/\n",
    "\n",
    "│   ├── image1.jpg\n",
    "\n",
    "│   ├── image2.jpg\n",
    "\n",
    "│   ├── ...\n",
    "\n",
    "├── ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "# Define the root directory where your dataset is stored\n",
    "data_dir = 'path/to/dataset/'\n",
    "\n",
    "# Create an ImageFolder dataset\n",
    "dataset = datasets.ImageFolder(data_dir, transform=my_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader\n",
    "DataLoader is a utility class that is used to efficiently load and manage data for training deep learning models, especially when dealing with large datasets. It is an essential component when working with tasks like image classification, object detection, natural language processing, and more. The primary purpose of a DataLoader is to provide an iterable over a dataset, which can be easily integrated into the training loop of your machine learning model. Here's how a DataLoader works and why it's useful:\n",
    "\n",
    "* Dataset: The foundation of a DataLoader is a PyTorch dataset. A dataset is an abstraction that represents your data and provides methods to access and manipulate it. PyTorch provides several built-in datasets, and you can also create custom datasets by subclassing the torch.utils.data.Dataset class. Datasets are usually responsible for loading and preprocessing the data samples.\n",
    "\n",
    "* Batching: Training deep learning models is often done in batches of data samples rather than individual samples. Batching allows for efficient vectorized operations on a GPU, which speeds up training. The DataLoader takes care of dividing your dataset into batches of a specified size.\n",
    "\n",
    "* Shuffling: It's common practice to shuffle the data before each epoch (a complete pass through the entire dataset). Shuffling helps in reducing any ordering bias that may exist in the data. The DataLoader can shuffle your dataset automatically if you set the shuffle parameter to True.\n",
    "\n",
    "* Parallel Data Loading: If you have a multi-core CPU or multiple GPUs, you can take advantage of parallel data loading. The DataLoader can load multiple batches in parallel, which can significantly speed up the training process.\n",
    "\n",
    "* Iterability: DataLoader provides an iterable object that you can use in a for loop during training. It automatically takes care of loading and batching the data, making it easy to integrate into your training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "shuffle = True\n",
    "\n",
    "custom_dataset = CustomCIFAR10(transform=custom_transform)\n",
    "data_loader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Techniques\n",
    "\n",
    "Efficient data preprocessing and loading are essential for training robust machine learning models. In this section, we'll cover various techniques to preprocess your data effectively using PyTorch.\n",
    "\n",
    "## Data Batching and Shuffling\n",
    "During model training, it's common to process data in batches rather than individually. Batching not only improves computational efficiency but also provides a form of regularization. Additionally, shuffling the data within each epoch helps prevent the model from memorizing the order of the samples. PyTorch's DataLoader makes it easy to handle batching and shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create a DataLoader with a batch size\n",
    "batch_size = 32\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Transforms\n",
    "PyTorch provides a powerful set of transformation functions in the torchvision.transforms module that can be applied to your datasets. These transformations are particularly useful for preprocessing and augmenting image data\n",
    "\n",
    "## Common Transforms\n",
    "PyTorch transforms can perform a wide range of operations, including resizing, cropping, rotation, and normalization. Here are some common transforms we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Resize images to a specific size\n",
    "resize_transform = transforms.Resize((128, 128))\n",
    "\n",
    "# Randomly flip images horizontally \n",
    "flip_transform = transforms.RandomHorizontalFlip()\n",
    "\n",
    "# Convert images to PyTorch tensors\n",
    "tensor_transform = transforms.ToTensor()\n",
    "\n",
    "# Normalize image values with mean and standard deviation\n",
    "normalize_transform = transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Transforms\n",
    "You can create a sequence of transforms and apply them to your data using the transforms.Compose function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define individual transformations\n",
    "resize_transform = transforms.Resize((256, 256))  # Resize the image to 256x256 pixels\n",
    "flip_transform = transforms.RandomHorizontalFlip()  # Randomly flip the image horizontally\n",
    "\n",
    "# Combine multiple transforms into a single transform pipeline\n",
    "transform = transforms.Compose([resize_transform, flip_transform])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Data augmentation is a technique used to increase the diversity of the training dataset by applying random transformations such as rotations, flips, and crops. This helps the model generalize better and become more robust to variations in the data. Here's an example of data augmentation for CIFAR-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_stdlib_context\n",
    "\n",
    "# Define data augmentation and transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
    "    transforms.RandomRotation(10),       # Randomly rotate images by up to 10 degrees\n",
    "    transforms.RandomCrop(32, padding=4), # Randomly crop images with padding\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Apply transformations (including augmentation) to the dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch's nn.utils.rnn for Sequential Data\n",
    "When dealing with sequential data like text, time series, or audio, it's crucial to maintain the temporal structure of the data. PyTorch's nn.utils.rnn module provides tools to efficiently work with sequences, including padding and packing sequences for RNNs.\n",
    "\n",
    "## Sequence Padding\n",
    "In many real-world scenarios, sequences may have varying lengths. This can be problematic when you want to batch sequences for deep learning models. PyTorch's pad_sequence function is a valuable tool for handling sequences of different lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1, 2, 3]), tensor([4, 5]), tensor([6, 7, 8, 9])]\n",
      "\n",
      "tensor([[1, 2, 3, 0],\n",
      "        [4, 5, 0, 0],\n",
      "        [6, 7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "sequences = [torch.tensor([1, 2, 3]), torch.tensor([4, 5]), torch.tensor([6, 7, 8, 9])]\n",
    "padded_sequences = rnn_utils.pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "print(sequences)\n",
    "print()\n",
    "print(padded_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Custom Datasets\n",
    "\n",
    "In some machine learning and deep learning projects, we may need to work with custom datasets that are not available as built-in datasets. PyTorch allows you to create custom datasets by subclassing the ```torch.utils.data.Dataset``` class. In this section, we'll explore how to create custom datasets tailored to our specific needs\n",
    "\n",
    "### Dataset Class\n",
    "To create a custom dataset, we'll need to define a Python class that inherits from ```torch.utils.data.Dataset```. This class should implement the following methods:\n",
    "\n",
    "```__init__(self)```: Initialize the dataset and load data if necessary\n",
    "\n",
    "```__len__(self)```: Return the total number of samples in the dataset\n",
    "\n",
    "```__getitem__(self, idx)```: Return a data sample and its corresponding label for the given index idx\n",
    "\n",
    "Example of how to create a custom dataset for classifying images of cats and dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "class CustomCatDogDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "        self.labels = [0 if 'cat' in filename else 1 for filename in os.listdir(data_dir)]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "custom_dataset = CustomCatDogDataset(data_dir='./custom_dataset', transform=data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training DL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in ./.venv/lib/python3.8/site-packages (2.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Language Processing (NLP) related imports\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Regular expressions\n",
    "import re\n",
    "import torch\n",
    "\n",
    "# Machine learning and deep learning frameworks\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Data preprocessing for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(X_train, y_train, X_val=None, y_val=None, dataset_class=None, batch_size=64):\n",
    "    \"\"\"\n",
    "    Load and preprocess data into PyTorch data loaders for training and validation.\n",
    "\n",
    "    Args:\n",
    "        X_train (numpy.ndarray): Training data features.\n",
    "        y_train (numpy.ndarray): Training data labels.\n",
    "        X_val (numpy.ndarray, optional): Validation data features.\n",
    "        y_val (numpy.ndarray, optional): Validation data labels.\n",
    "        dataset_class (class, optional): Custom dataset class to create datasets.\n",
    "        batch_size (int, optional): Batch size for data loaders. Default is 64.\n",
    "\n",
    "    Returns:\n",
    "        train_loader (DataLoader): Data loader for training data.\n",
    "        val_loader (DataLoader or None): Data loader for validation data, or None if validation data is not provided.\n",
    "    \"\"\"\n",
    "\n",
    "    train_data = dataset_class(data=X_train, labels=y_train)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_loader = None\n",
    "\n",
    "    if X_val is not None and y_val is not None and dataset_class is not None:\n",
    "        val_data = dataset_class(data=X_val, labels=y_val)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device='cpu'):\n",
    "    \"\"\"\n",
    "    Validate a trained deep learning model on a validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained neural network model to validate.\n",
    "        val_loader (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
    "        criterion (torch.nn.Module): The loss function used for validation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the validation loss and validation accuracy (in percentage).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    correct_val_predictions = 0\n",
    "    total_val_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in val_loader:\n",
    "            val_inputs = data.to(device)\n",
    "            val_labels = labels.to(device)\n",
    "\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "            # Calculate validation accuracy\n",
    "            _, predicted_val = torch.max(val_outputs, 1)\n",
    "            correct_val_predictions += (predicted_val == val_labels).sum().item()\n",
    "            total_val_samples += val_labels.size(0)\n",
    "\n",
    "    validation_accuracy = correct_val_predictions / total_val_samples\n",
    "    return total_val_loss / len(val_loader), validation_accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion,\n",
    "          scheduler=None, val_loader=None, epochs=10, device='cpu'):\n",
    "    \"\"\"\n",
    "    Train a deep learning model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to train.\n",
    "        train_loader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "        val_loader (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
    "        criterion (torch.nn.Module): The loss function used for training.\n",
    "        epochs (int, optional): The number of training epochs. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        correct_train_predictions = 0\n",
    "        total_train_samples = 0\n",
    "\n",
    "        for data, labels in train_loader:\n",
    "            inputs = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            _, predicted_train = torch.max(outputs, 1)\n",
    "            correct_train_predictions += (predicted_train == labels).sum().item()\n",
    "            total_train_samples += labels.size(0)\n",
    "\n",
    "        training_accuracy = correct_train_predictions / total_train_samples\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Training Loss: {total_loss / len(train_loader):.3f}, Training Accuracy: {training_accuracy * 100:.3f}%')\n",
    "        \n",
    "        if val_loader is not None:\n",
    "            # Validation step using the callback\n",
    "            val_loss, val_accuracy = validate(model, val_loader, criterion,device=device)\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss:.3f}, Validation Accuracy: {val_accuracy:.3f}%\\n')\n",
    "\n",
    "    print('Training finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some sample data\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1)  # Input features (100 samples)\n",
    "y = 2 * X + 1 + 0.1 * np.random.randn(100, 1)  # Corresponding labels with some noise\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linear regression model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)  # One input feature, one output\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define the loss function (Mean Squared Error)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Stochastic Gradient Descent)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/5000], Loss: 0.0356\n",
      "Epoch [1000/5000], Loss: 0.0148\n",
      "Epoch [1500/5000], Loss: 0.0097\n",
      "Epoch [2000/5000], Loss: 0.0085\n",
      "Epoch [2500/5000], Loss: 0.0082\n",
      "Epoch [3000/5000], Loss: 0.0081\n",
      "Epoch [3500/5000], Loss: 0.0081\n",
      "Epoch [4000/5000], Loss: 0.0081\n",
      "Epoch [4500/5000], Loss: 0.0081\n",
      "Epoch [5000/5000], Loss: 0.0081\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_tensor)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "    \n",
    "    # Backpropagation and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Neural Network on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0          5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1          0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2          4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3          1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4          9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "59995      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59996      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59997      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59998      6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "59999      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0          0      0      0      0      0      0      0      0  \n",
       "1          0      0      0      0      0      0      0      0  \n",
       "2          0      0      0      0      0      0      0      0  \n",
       "3          0      0      0      0      0      0      0      0  \n",
       "4          0      0      0      0      0      0      0      0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "59995      0      0      0      0      0      0      0      0  \n",
       "59996      0      0      0      0      0      0      0      0  \n",
       "59997      0      0      0      0      0      0      0      0  \n",
       "59998      0      0      0      0      0      0      0      0  \n",
       "59999      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[60000 rows x 785 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"mnist/mnist_train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:].values  # set training data\n",
    "y = df.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomMnistDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, shuffle=True):\n",
    "        self.data = data.astype(np.float32)\n",
    "        self.labels = labels.astype(np.int64)\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = load_data(X_train, y_train, X_val, y_val, CustomMnistDataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "num_classes = 10\n",
    "num_epochs = 50\n",
    "\n",
    "model = SimpleNN(input_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.688, Training Accuracy: 89.406%\n",
      "Epoch [1/10], Validation Loss: 0.250, Validation Accuracy: 93.350%\n",
      "\n",
      "Epoch [2/10], Training Loss: 0.200, Training Accuracy: 94.510%\n",
      "Epoch [2/10], Validation Loss: 0.198, Validation Accuracy: 94.708%\n",
      "\n",
      "Epoch [3/10], Training Loss: 0.169, Training Accuracy: 95.317%\n",
      "Epoch [3/10], Validation Loss: 0.194, Validation Accuracy: 94.633%\n",
      "\n",
      "Epoch [4/10], Training Loss: 0.159, Training Accuracy: 95.690%\n",
      "Epoch [4/10], Validation Loss: 0.195, Validation Accuracy: 94.992%\n",
      "\n",
      "Epoch [5/10], Training Loss: 0.142, Training Accuracy: 96.060%\n",
      "Epoch [5/10], Validation Loss: 0.280, Validation Accuracy: 93.975%\n",
      "\n",
      "Epoch [6/10], Training Loss: 0.148, Training Accuracy: 96.085%\n",
      "Epoch [6/10], Validation Loss: 0.199, Validation Accuracy: 95.650%\n",
      "\n",
      "Epoch [7/10], Training Loss: 0.138, Training Accuracy: 96.213%\n",
      "Epoch [7/10], Validation Loss: 0.209, Validation Accuracy: 95.167%\n",
      "\n",
      "Epoch [8/10], Training Loss: 0.138, Training Accuracy: 96.427%\n",
      "Epoch [8/10], Validation Loss: 0.248, Validation Accuracy: 94.433%\n",
      "\n",
      "Epoch [9/10], Training Loss: 0.137, Training Accuracy: 96.510%\n",
      "Epoch [9/10], Validation Loss: 0.263, Validation Accuracy: 94.417%\n",
      "\n",
      "Epoch [10/10], Training Loss: 0.121, Training Accuracy: 96.802%\n",
      "Epoch [10/10], Validation Loss: 0.222, Validation Accuracy: 95.625%\n",
      "\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, optimizer, criterion, \n",
    "          val_loader=val_loader, epochs=10, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
