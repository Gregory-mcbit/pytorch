{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "PyTorch is a deep learning framework used for research and development in machine learning and artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor is a fundamental data structure that is similar to arrays or matrices. Tensors are the building blocks of neural networks and are used to represent data in the form of multi-dimensional arrays\n",
    "\n",
    "### Types of Tensors\n",
    "![](./Tensor.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3729,  0.5235,  0.0917,  ...,  0.5436,  1.0157, -0.4076],\n",
       "         [-0.8359,  0.4857, -0.3840,  ...,  1.2926,  0.0419,  0.0745],\n",
       "         [-1.0659,  1.0442, -0.0694,  ...,  0.5912, -0.3699,  2.1489],\n",
       "         ...,\n",
       "         [ 1.2287, -0.8064, -1.9017,  ...,  2.2413,  1.2596,  0.3129],\n",
       "         [-0.4460,  0.7702, -0.4863,  ..., -1.1460,  1.3075, -0.5704],\n",
       "         [ 1.1359, -0.1912, -0.3292,  ..., -1.0832,  0.7019, -2.3536]],\n",
       "\n",
       "        [[-0.3411,  1.1427,  0.0199,  ..., -0.4445, -0.0500, -0.7401],\n",
       "         [ 0.5400, -1.0509,  0.3330,  ..., -0.4529,  0.2833, -1.2745],\n",
       "         [ 1.3937,  1.5880,  1.5692,  ..., -1.0110, -0.2030,  0.1606],\n",
       "         ...,\n",
       "         [ 0.9348,  0.2876, -0.7562,  ...,  0.1915, -1.4093,  0.6099],\n",
       "         [ 0.1194, -0.4032, -0.5989,  ..., -0.1392, -0.2586, -0.2671],\n",
       "         [ 0.8928, -1.5127,  0.3421,  ..., -0.6807, -0.1817,  1.4142]],\n",
       "\n",
       "        [[ 0.1711, -0.1057, -1.1131,  ..., -2.4121,  0.7486, -0.1343],\n",
       "         [ 0.1748,  0.4051, -0.2572,  ...,  0.5990, -3.1854,  0.4859],\n",
       "         [-0.7800,  1.4479,  0.1277,  ...,  1.1154,  1.4639,  1.1680],\n",
       "         ...,\n",
       "         [ 1.1636,  0.5830,  0.9910,  ..., -0.9185,  1.6295, -0.7773],\n",
       "         [-0.2162, -1.0876, -0.5299,  ...,  1.8885, -0.6064,  3.3585],\n",
       "         [-0.6892, -1.8988, -1.7454,  ..., -1.6540,  0.0334,  0.0357]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(42.0)  # Creates a scalar tensor with the value 42.0. has 0 dimensions\n",
    "vector = torch.tensor([1, 2, 3, 4, 5])  # Creates a 1-D tensor with 5 elements\n",
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])  # Creates a 2-D tensor with 2 rows and 3 columns\n",
    "four_dim_tensor = torch.randn(32, 3, 64, 64)  # Create a 4-D tensor with shape (batch_size, channels, height, width)\n",
    "four_dim_tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different arguments can be provided for tensor creation:\n",
    "* Data\n",
    "* Dtype\n",
    "* Device (specify the device (CPU or GPU) on which the tensor should be located using this argument. If not provided, the tensor will be created on the CPU by default.)\n",
    "* Requires_grad (If set to True, the tensor will be set up to track operations on it for automatic differentiation (autograd) during backpropagation. This is useful for gradient-based optimization and training deep learning models.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor(data=[[1, 2, 3], [4, 5, 6]], \n",
    "dtype=torch.float32, \n",
    "device='cpu', \n",
    "requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor(data=[[1, 2, 3], [3, 2, 3]])\n",
    "tensor.type(torch.float32)\n",
    "tensor.numel()  # total elements in tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 3],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor = torch.reshape(tensor, (3, 2))\n",
    "reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 3],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor = torch.reshape(tensor, (-1, 2))  # -1 is used to infer one of dimensions\n",
    "reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2488, -0.4536,  0.2434,  ..., -0.5588,  0.4220, -0.0659],\n",
       "        [-0.6298,  0.5623, -1.7265,  ..., -1.4979, -1.2487, -0.0790],\n",
       "        [-0.4422,  1.1159, -0.8890,  ...,  0.8135,  0.0231,  1.6736],\n",
       "        ...,\n",
       "        [ 1.4524, -0.4520,  0.1751,  ...,  1.8863,  1.6410,  0.8342],\n",
       "        [ 1.2307,  0.7091, -1.0273,  ..., -0.4876, -2.5519, -1.0745],\n",
       "        [ 0.9052, -1.2224,  0.6602,  ...,  0.3539,  0.4184,  0.8794]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(32, 3, 64, 64)\n",
    "x_flattened = x.view(x.size(0), -1)\n",
    "x_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_tensor = torch.unsqueeze(tensor, dim=0)  #  Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "expanded_tensor.size(), tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permute function\n",
    "The permute() function allows to rearrange dimensions in a tensor, providing with the flexibility to change the shape and orientation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted_tensor = tensor.permute(1, 0)  # Swap dimensions 0 and 1\n",
    "permuted_tensor.shape, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [3, 2, 3]]),\n",
       " tensor([[1, 3],\n",
       "         [2, 2],\n",
       "         [3, 3]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor, permuted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original tensor shape is: torch.Size([2, 3]),\n",
      "The transposed tensor using .t shape is: torch.Size([3, 2]),\n",
      "The transposed tensor using .tranpose shape is: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Transposing a Tensor (Swapping Rows and Columns)\n",
    "transposed_tensor_1 = tensor.t()\n",
    "transposed_tensor_2 = torch.transpose(tensor, 0, 1)  # Swap axes 0 and 1\n",
    "\n",
    "print(f'The original tensor shape is: {tensor.shape},\\n' \n",
    "      f'The transposed tensor using .t shape is: {transposed_tensor_1.shape},\\n' \n",
    "      f'The transposed tensor using .tranpose shape is: {transposed_tensor_2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition and subtraction between tensors same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9,  9, 10],\n",
       "        [17, 17,  7]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a = torch.tensor([[4, 5, 7], [8, 9, 0]])\n",
    "tensor_b = torch.tensor([[5, 4, 3], [9, 8, 7]])\n",
    "\n",
    "tensor_a + tensor_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1,  1,  4],\n",
       "        [-1,  1, -7]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a - tensor_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element-wise multiplication between 2 tensors of same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20, 20, 21],\n",
       "        [72, 72,  0]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a * tensor_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix-wise multiplication (dot product) between 2 tensors where the inner dimensions match (the number of columns in the first tensor equals the number of rows in the second tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 72,  63,  54],\n",
       "        [121, 104,  87]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_c = torch.tensor([[5, 4, 3], [9, 8, 7], [1, 1, 1]])\n",
    "matmu = torch.matmul(tensor_a, tensor_c)\n",
    "matmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8000, 1.2500, 2.3333],\n",
       "        [0.8889, 1.1250, 0.0000]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div = tensor_a / tensor_b\n",
    "div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     1024,       625,       343],\n",
       "        [134217728,  43046721,         0]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_exp = tensor_a ** tensor_b\n",
    "result_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000, 2.2361, 2.6458],\n",
       "        [2.8284, 3.0000, 0.0000]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_sqrt = torch.sqrt(tensor_a)\n",
    "result_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3863, 1.6094, 1.9459],\n",
       "        [2.0794, 2.1972,   -inf]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_log = torch.log(tensor_a)  # natural logarithm (base e)\n",
    "result_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(33.),\n",
       " tensor([5.3333, 5.6667]),\n",
       " torch.return_types.max(\n",
       " values=tensor([8., 9., 7.]),\n",
       " indices=tensor([1, 1, 0])),\n",
       " torch.return_types.min(\n",
       " values=tensor([4., 0.]),\n",
       " indices=tensor([0, 2])))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a = tensor_a.type(torch.float32)\n",
    "total_sum = torch.sum(tensor_a)\n",
    "\n",
    "# Compute the mean along axis 1 (rows)\n",
    "mean_along_rows = torch.mean(tensor_a, dim=1)\n",
    "\n",
    "# Compute the maximum value along axis 0 (columns)\n",
    "max_along_columns = torch.max(tensor_a, dim=0)\n",
    "\n",
    "# Compute the minimum value along axis 1 (rows)\n",
    "min_along_rows = torch.min(tensor_a, dim=1)\n",
    "\n",
    "total_sum, mean_along_rows, max_along_columns, min_along_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting in PyTorch\n",
    "\n",
    "The key idea behind broadcasting is that the smaller tensor is \"broadcasted\" or expanded to match the shape of the larger one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broadcast results is: tensor([[ 6.,  7.,  9.],\n",
      "        [10., 11.,  2.]]) and of shape torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "scalar = 2\n",
    "result_broadcast = tensor_a + scalar\n",
    "print(f'broadcast results is: {result_broadcast} and of shape {result_broadcast.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two 2x2 tensors, tensor_a and tensor_b, and we want to concatenate them along dimension 0 to create a new tensor with a shape of 4x2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenated tensor is: tensor([[2, 2],\n",
      "        [2, 2],\n",
      "        [4, 4],\n",
      "        [4, 4]]) and of shape torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor_a, tensor_b = torch.tensor([[2, 2], [2, 2]]), torch.tensor([[4, 4], [4, 4]])\n",
    "concatenated_tensor = torch.cat((tensor_a, tensor_b), dim=0)\n",
    "print(f'concatenated tensor is: {concatenated_tensor} and of shape {concatenated_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGrad and Gradients\n",
    "\n",
    "Autograd, short for Automatic Differentiation, is a key feature of PyTorch that allows for automatic computation of gradients (derivatives) of tensors. It is an essential component for training deep learning models through backpropagation.\n",
    "1. **Gradient Calculation** - In deep learning, we often need to compute gradients of a loss function with respect to model parameters. Autograd simplifies this process. When you perform operations on tensors that require gradients, PyTorch automatically tracks these operations and constructs a computation graph.\n",
    "\n",
    "2. **Computation Graph** - A computation graph is a directed acyclic graph (DAG) that represents the sequence of operations applied to tensors. Each operation in the graph is a node, and tensors flowing through these nodes are edges. The graph allows PyTorch to trace how input tensors influence the output tensors, which is crucial for gradient calculation.\n",
    "\n",
    "3. **Dynamic Computational Graph** - PyTorch uses a dynamic computation graph, which means the graph is built on-the-fly as operations are executed. This dynamic nature allows flexibility and is well-suited for models with varying architectures or inputs of different shapes.\n",
    "\n",
    "4. **Gradients** - Once you have a computation graph, you can compute gradients by backpropagating through the graph. Gradients represent how a small change in each input tensor would affect the final output. The gradients are computed using the chain rule of calculus, and they indicate the direction and magnitude of parameter updates during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
